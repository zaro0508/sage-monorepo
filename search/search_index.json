{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sage Monorepo","text":""},{"location":"#sage-monorepo","title":"Sage Monorepo","text":"<p>Build robust apps faster</p> <p> </p> <p>Developers building components in silos can lead to a number of problems, including duplicated components, increased maintenance, and reduced visibility.</p> <p>Sage Monorepo addresses these problems by providing a centralized repository for standardized, reusable components. This solution also improves the developer experience (DX), which can lead to increased morale, productivity, retention, and knowledge transfer.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Build apps faster</li> <li>Use latest technologies</li> <li>Open-source</li> </ul>"},{"location":"#current-projects","title":"Current Projects","text":"Name Description Agora Agora hosts high-dimensional human transcriptomic, proteomic, and metabolomic evidence for whether or not genes are associated with Alzheimer\u2019s disease (AD). iAtlas The iAtlas portal serves as an interactive tool for exploring and analyzing immuno-oncology data. OpenChallenges OpenChallenges (OC) aggregates biomedical challenges to accelerate citizen science and data benchmarking Schematic SCHEMATIC (Schema Engine for Manifest Ingress and Curation) is a novel schema-based, metadata ingress ecosystem, meant to streamline the process of biomedical dataset annotation, metadata validation and submission to a data repository for various data contributors."},{"location":"news/","title":"What's new","text":""},{"location":"news/#general","title":"General","text":""},{"location":"news/#jan-2024","title":"Jan 2024","text":"<p>We're kicking off the new year with our new-and-improved docs site!  We are continuously looking to improve, so if you have any feedback, please us know!</p>"},{"location":"news/#sept-2023","title":"Sept 2023","text":"<p>Introducing a new product we support: Agora!</p>"},{"location":"news/#june-2023","title":"June 2023","text":"<p>We now support the schematic API! Check them out.</p>"},{"location":"news/#jan-2023","title":"Jan 2023","text":"<p>Kicking off the Sage Monorepo with our first product: OpenChallenges</p>"},{"location":"news/#agora","title":"Agora","text":""},{"location":"news/#openchallenges","title":"OpenChallenges","text":""},{"location":"news/#schematic","title":"Schematic","text":""},{"location":"_archive/","title":"Index","text":"<ul> <li>Overview of Sage Monorepo</li> <li>Cheat Sheet (coming soon)</li> <li>Docs</li> </ul>"},{"location":"_archive/#development-setup","title":"Development Setup","text":""},{"location":"_archive/#requirements","title":"Requirements","text":"<ul> <li>Docker Engine OR GitHub Codespace</li> <li>Visual Studio Code</li> </ul>"},{"location":"_archive/#open-sage-monorepo-in-vs-code","title":"Open Sage Monorepo in VS Code","text":"<p>Option 1: Click on the button shown below to open Sage Monorepo in its development container with VS Code. This option is suitable if you want to explore the content of Sage Monorepo.</p> <p></p> <p>Option 2: If you plan to contribute to this project, please create a fork and use its URL for cloning. For more information on contributing and/or our Forking Workflow, see CONTRIBUTING.md.</p> git clone --filter=blob:none &lt;fork url&gt;Resolving deltas: 100% (...), done. <p>Then open your fork repo inside our dev container using these instructions:</p> <ul> <li>Developing inside a Container</li> <li>Develop on a remote host (optional)</li> </ul>"},{"location":"_archive/#ecosystem","title":"Ecosystem","text":"<ul> <li>Java</li> <li>Node.js</li> <li>Python</li> <li>R</li> </ul>"},{"location":"_archive/#projects","title":"Projects","text":"<ul> <li>OpenChallenges</li> <li>Schematic (evaluation)</li> <li>Synapse (evaluation)</li> </ul> <p>Love Sage Monorepo and its projects? Give our repo a star \u2b50.</p>"},{"location":"_archive/angular-universal/","title":"Angular universal","text":"<p>The article Angular Universal: a Complete Practical Guide offers an excellent introduction to Angular Universal, server-side rendering (SSR) and search engine optimization (SEO).</p>"},{"location":"_archive/angular-universal/#why-angular-universal","title":"Why Angular Universal?","text":"<ul> <li>Improve the startup performance of our application.</li> <li>Make our application more search engine friendly.</li> <li>Most search engine crawlers expect these important SEO meta tags to be present on the HTML     returned by the server, and not to modified at runtime by Javascript as done with client-side     rendering (CSR).</li> <li>If we are targetting only the Google search engine, as we have shown there is no need to     server-side render our content in order to have it ranked correctly, as Google can today index     correctly most Javascript-based content.</li> <li>Improve the social media presence of our application.</li> <li>Enable social media crawlers to crawl our application pages.</li> </ul>"},{"location":"_archive/angular-universal/#about-angular-aot-compilation-and-srr-rendering","title":"About Angular AOT compilation and SRR rendering","text":"<p>The Angular AOT compiler converts your Angular HTML and TS code into efficient JavaScript code\" (angular.io/guide/aot-compiler). That code is still run on client-side to render the first and every other view. SSR is not an alternative but an additional technique to further increase performance for first-time visitors and SEO, as the first view is rendered on server side and the client receives that assembled and styled HTML, so there is no need to dynamically render anything at the beginning.</p> <p>Martin Schneider Aug 26, 2021 at 14:15 (source)</p>"},{"location":"_archive/angular-universal/#create-an-angular-universal-application","title":"Create an Angular Universal application","text":"<p>We are going to go start with an existing Angular application, and we will progressively turn it into an Angular Universal application while explaining every step along the way!</p> <p>The second part of the instructions describe how to tweak the app to meet the need of this project. The previous version of the OpenChallenges app generated in early 2022 is referenced as the \"legacy\" app.</p> <ol> <li>Create an Angular app.</li> </ol> <pre><code>nx generate @nx/angular:app openchallenges --routing=true --style=scss\n</code></pre> <p>Note Add the option <code>--dry-run</code> to preview the output of Nx commands.</p> <p>Note The legacy OpenChallenges app generated early 2022 was build with the generator <code>@nx/angular:webpack-browser</code>. The newly generated app is now built with <code>@angular-devkit/build-angular:browser</code> (see <code>project.json</code>).</p> <ol> <li>Let's use the Angular Universal schematic to initialize our SSR setup for the    <code>openchallenges</code> application by running the following in the terminal:</li> </ol> <pre><code>nx generate @schematics/angular:universal --project=openchallenges\n</code></pre> <ol> <li> <p>Follow the instructions listed in the article Server-side rendering (SSR) with Angular for Nx    workspaces to add the project target <code>serve-ssr</code>.</p> </li> <li> <p>Delete the folder <code>src/assets</code> and <code>src/environments</code>. Import the folder <code>src/assets</code> and    <code>src/config</code> from the legacy OpenChallenges app.</p> </li> <li> <p>Update <code>project.json</code></p> </li> <li> <p>Add this line to the top of <code>project.json</code> is missing.</p> <pre><code>\"$schema\": \"../../node_modules/nx/schemas/project-schema.json\",\n</code></pre> </li> <li> <p>Update the value of <code>prefix</code>.</p> <pre><code>\"prefix\": \"openchallenges\",\n</code></pre> </li> <li> <p>Copy-paste the following targets from the legacy app.</p> <ul> <li><code>prepare</code></li> <li><code>lint-fix</code></li> <li><code>build-image</code></li> </ul> </li> <li> <p>Update the value of <code>assets</code> specified in the <code>build</code> target.</p> <pre><code>\"assets\": [\n  \"apps/openchallenges/src/assets\",\n  \"apps/openchallenges/src/config\",\n  {\n    \"input\": \"libs/shared/typescript/assets/src/assets\",\n    \"glob\": \"**/*\",\n    \"output\": \"assets\"\n  },\n  {\n    \"input\": \"libs/openchallenges/assets/src/assets\",\n    \"glob\": \"**/*\",\n    \"output\": \"openchallenges-assets\"\n  },\n  {\n    \"input\": \"libs/shared/typescript/assets/src\",\n    \"glob\": \"favicon.ico\",\n    \"output\": \"\"\n  }\n],\n</code></pre> </li> <li> <p>Update the value of <code>budgets</code> in the <code>configurations</code> object of the <code>build</code> target.</p> <pre><code>\"budgets\": [\n  {\n    \"type\": \"initial\",\n    \"maximumWarning\": \"500kb\",\n    \"maximumError\": \"1mb\"\n  },\n  {\n    \"type\": \"anyComponentStyle\",\n    \"maximumWarning\": \"2kb\",\n    \"maximumError\": \"8kb\"\n  }\n],\n</code></pre> </li> <li> <p>Empty the array value of <code>fileReplacements</code> in the <code>configurations</code> object of the      <code>build</code> target.</p> </li> <li> <p>Set the project <code>tags</code>.</p> <pre><code>\"tags\": [\n  \"type:app\",\n  \"scope:client\"\n],\n</code></pre> </li> <li> <p>Set the project <code>implicitDependencies</code>.      <pre><code>\"implicitDependencies\": [\n  \"openchallenges-styles\",\n  \"openchallenges-themes\",\n  \"shared-typescript-assets\",\n  \"openchallenges-api-gateway\",\n  \"openchallenges-keycloak\"\n]\n</code></pre></p> </li> <li> <p>Replace the content of the <code>src/main.ts</code> with the following code to make use of the   configuration defined in the folder <code>src/config</code> to enable Build once, deploy many.</p> </li> </ol> <pre><code>import { enableProdMode } from '@angular/core';\nimport { platformBrowserDynamic } from '@angular/platform-browser-dynamic';\n\nimport { AppModule } from './app/app.module';\nimport {\n  AppConfig,\n  APP_CONFIG,\n  Environment,\n} from '@sagebionetworks/openchallenges/config';\n\nfunction bootstrap() {\n  fetch('/config/config.json')\n    .then((response) =&gt; response.json() as Promise&lt;AppConfig&gt;)\n    .then((config: AppConfig) =&gt; {\n      if (\n        [Environment.Production, Environment.Staging].includes(\n          config.environment\n        )\n      ) {\n        enableProdMode();\n      }\n\n      console.log('openchallenges config', config);\n\n      platformBrowserDynamic([{ provide: APP_CONFIG, useValue: config }])\n        .bootstrapModule(AppModule)\n        .catch((err) =&gt; console.error(err));\n    });\n}\n\nif (document.readyState === 'complete') {\n  bootstrap();\n} else {\n  document.addEventListener('DOMContentLoaded', bootstrap);\n}\n</code></pre> <ul> <li> <p>Update the <code>src</code> files based on the legacy code. These files include but are not limited to:</p> </li> <li> <p><code>src/app/*</code></p> </li> <li><code>_app-theme.scss</code></li> <li><code>src/index.html</code></li> <li><code>src/proxy.conf.json</code></li> <li> <p><code>styles.scss</code></p> </li> <li> <p>Update the files in the project folder based on their legacy version. These files include but   are not limited to:</p> </li> <li><code>docker/</code></li> <li><code>.eslintrc.json</code></li> <li><code>Dockerfile</code></li> </ul>"},{"location":"_archive/angular-universal/#build-the-angular-universal-bundle","title":"Build the Angular Universal Bundle","text":"<pre><code>nx server openchallenges --prod\n\n$ ls -alh dist/apps/openchallenges/server/\ntotal 5.3M\ndrwxr-xr-x 2 vscode vscode 4.0K Jul 28 15:39 .\ndrwxr-xr-x 3 vscode vscode 4.0K Jul 28 15:39 ..\n-rw-r--r-- 1 vscode vscode 174K Jul 28 15:39 297.js\n-rw-r--r-- 1 vscode vscode 112K Jul 28 15:39 3rdpartylicenses.txt\n-rw-r--r-- 1 vscode vscode 6.9K Jul 28 15:39 513.js\n-rw-r--r-- 1 vscode vscode  95K Jul 28 15:39 603.js\n-rw-r--r-- 1 vscode vscode 6.7K Jul 28 15:39 654.js\n-rw-r--r-- 1 vscode vscode 299K Jul 28 15:39 715.js\n-rw-r--r-- 1 vscode vscode 174K Jul 28 15:39 731.js\n-rw-r--r-- 1 vscode vscode 248K Jul 28 15:39 748.js\n-rw-r--r-- 1 vscode vscode  13K Jul 28 15:39 762.js\n-rw-r--r-- 1 vscode vscode 7.1K Jul 28 15:39 822.js\n-rw-r--r-- 1 vscode vscode 102K Jul 28 15:39 989.js\n-rw-r--r-- 1 vscode vscode 4.0M Jul 28 15:39 main.js\n</code></pre> <p>From Angular Universal: a Complete Practical Guide:</p> <p>We will need the production version of the Universal bundle, as the development bundle will not work.</p> <p>Really?</p>"},{"location":"_archive/angular-universal/#todo","title":"TODO","text":"<p>To review and adapt:</p> <pre><code># Development\nnpm run start\nhttp://localhost:4200/\n\n# Tests\nnpm run lint\nnpm run test\nnpm run e2e\n\n# AOT Compilation\nnpm run build\n\n# SSR Compilation\nnpm run build:ssr\nnpm run serve:ssr\nhttp://localhost:4000/\n</code></pre>"},{"location":"_archive/angular-universal/#references","title":"References","text":"<ul> <li>Server-side rendering (SSR) with Angular Universal</li> <li>Angular Universal: a Complete Practical Guide</li> <li>Rendering on the Web</li> <li>Server-side rendering (SSR) with Angular for Nx workspaces</li> </ul>"},{"location":"_archive/app-styles-themes-assets/","title":"App styles themes assets","text":"<p>This document describes how SCSS styles, themes and assets are organized across a web app and its libraries.</p>"},{"location":"_archive/app-styles-themes-assets/#file-structure","title":"File Structure","text":"<p>Each Angular component has its own style file (css, scss, less, etc). When building the app, Angular includes the component style files into the app style bundle. Additional styling files are used in our applications. These files are organized as shown below.</p> <pre><code>apps/\n\u2514\u2500 web-app/\n   \u2514\u2500 src/\n      \u251c\u2500 _app-themes.scss               &lt;---- app styles (2)\n      \u251c\u2500 index.html\n      \u2514\u2500 styles.scss                    &lt;---- app styles (1)\ndist/\n\u2514\u2500 apps/\n   \u2514\u2500 web-app/\n      \u251c\u2500 index.html\n      \u2514\u2500 styles.&lt;hash&gt;.css              &lt;---- app style bundle (7)\nlibs/\n\u251c\u2500 shared/\n\u2502  \u251c\u2500 assets/                           &lt;---- cross-app assets\n\u2502  \u251c\u2500 styles/                           &lt;---- cross-app styles (5)\n\u2502  \u2514\u2500 themes/                           &lt;---- cross-app assets (6)\n\u2514\u2500 web/\n   \u251c\u2500 assets/                           &lt;---- app-specific assets\n   \u251c\u2500 styles/                           &lt;---- app-specific styles (3)\n   \u2514\u2500 themes/                           &lt;---- app-specific assets (4)\n</code></pre> <ol> <li>The app style - This file imports the app styles defined in the app library <code>libs/web/styles</code> and    the app themes defined in <code>apps/web-app/src/_app-themes.scss</code>. This file is referenced in the    build options defined in the <code>project.json</code> of the app.</li> <li>The app theme - This file defines the theme configuration of the app (color and typography). This    file imports the themes defined in the app library <code>libs/web/themes</code>.</li> <li>The app styles library - This library defines the styles of the application. This library extends    the cross-app styles defined in <code>libs/shared/typescript/styles</code>.</li> <li>The app themes library - This library references the theme files of all the components defined in    <code>libs/web</code>.</li> <li>The cross-app style library - This library defines styles shared accross applications.</li> <li>The cross-app theme library - This library defined themes shared across applications.</li> <li>The app style bundle - This bundle includes the styles of the Angular components as well as the    app style and theme files of the app.</li> </ol> <p>Assets like images are used in HTML and SCSS files. Assets that are shared across applications are stored in <code>libs/shared/typescript/assets</code>. Assets that are specific to an app are located in <code>libs/&lt;app&gt;/assets</code> (e.g., where <code>libs/web/assets</code>). In order to use these assets in the app and libraries of the <code>web-app</code> application, the path to the asset folders are referenced in the build options of the app (see <code>project.json</code>). This is also where a prefix is defined to distinguish the asset files from these libraries. This example shows how to import an image from the cross-app and app-specific asset libraries.</p> <pre><code>&lt;img src=\"/shared-typescript-assets/images/github.png\"&gt;\n&lt;img src=\"/openchallenges-assets/images/challenge-view-header-background.png\"&gt;\n</code></pre>"},{"location":"_archive/app-styles-themes-assets/#applying-a-theme-to-a-component","title":"Applying a theme to a component","text":"<p>Create a file named <code>_&lt;component&gt;-theme.scss</code> that will be used to apply a theme to a component. While the style file of a component is responsible for the layout of the component, the theme file is responsible for defining the colors and typography of the component.</p> <pre><code>$ ls -1 libs/web/about/src/lib/\nabout.component.html\nabout.component.scss                   &lt;---- style file\nabout.component.spec.ts\nabout.component.ts\nabout.module.ts\n_about-theme.scss                      &lt;---- theme file\n</code></pre> <p>Seed the theme file with the following template:</p> <p>Note <code>@mixin color()</code> collects the color-related styles, <code>color</code> and <code>*-color</code> (i.e <code>background-color</code>), while the typography styles, <code>line-height</code> and <code>font-*</code> (i.e <code>font-size</code>), should be added into <code>@mixin typography()</code>.</p> <pre><code>@use 'sass:map';\n@use '@angular/material' as mat;\n\n@mixin color($theme) {\n  $config: mat.get-color-config($theme);\n  $primary: map.get($config, primary);\n  $accent: map.get($config, accent);\n  $warn: map.get($config, warn);\n  $background: map.get($config, background);\n  $foreground: map.get($config, foreground);\n\n  // Specify the colors of the elements of the component here.\n  // Example:\n  .awesome-class {\n    color: mat.get-color-from-palette($primary, default);\n  }\n}\n\n@mixin typography($theme) {\n  $config: mat.get-typography-config($theme);\n\n  // Specify the typography of the elements of the component here.\n  // Example:\n  .awesome-class {\n    font-family: mat.font-family($config);\n    font-size: mat.font-size($config);\n    font-weight: mat.font-weight($config);\n  }\n}\n\n@mixin theme($theme) {\n  $color-config: mat.get-color-config($theme);\n  @if $color-config != null {\n    @include color($theme);\n  }\n\n  $typography-config: mat.get-typography-config($theme);\n  @if $typography-config != null {\n    @include typography($theme);\n  }\n}\n</code></pre> <p>Reference the theme file created in the index theme file <code>_lib-theme.scss</code> of the library you are working on.</p> <pre><code>@use './lib/&lt;component&gt;-theme';                  &lt;---- import theme file\n@use './lib/&lt;component-2&gt;-theme';\n\n@mixin theme($theme) {\n  @include &lt;component&gt;-theme.theme($theme);      &lt;---- reference theme file\n  @include &lt;component-2&gt;-theme.theme($theme);\n}\n</code></pre> <p>If you are creating a new library, you need to reference the library index theme file in the index file of the <code>themes</code> library of the application. The <code>themes</code> library of the application <code>web-app</code> is located in <code>libs/web/themes</code>. Open its index file <code>libs/web/themes/src/_index.scss</code> and add the reference to the index theme file of the new library.</p> <pre><code>@use 'libs/web/&lt;lib&gt;/src/lib-theme' as web-&lt;lib&gt;;\n@use 'libs/web/&lt;lib-2&gt;/src/lib-theme' as web-&lt;lib-2&gt;;\n\n@mixin theme($theme) {\n  @include web-&lt;lib&gt;.theme($theme);\n  @include web-&lt;lib-2&gt;.theme($theme);\n}\n</code></pre> <p>The theme defined for the application should now be applied to the component.</p>"},{"location":"_archive/cheat-sheet/","title":"OpenChallenges Cheat Sheet","text":""},{"location":"_archive/cheat-sheet/#overview","title":"Overview","text":"<p>This cheat sheet provides an overview of the commands needed when developing in this monorepo.</p>"},{"location":"_archive/cheat-sheet/#workspace","title":"Workspace","text":"<p>The workspace of this monorepo was generated with:</p> <pre><code>yarn create nx-workspace openchallenges --preset=empty --packageManager=yarn\n</code></pre>"},{"location":"_archive/cheat-sheet/#project","title":"Project","text":"<p>Nx projects are created using a \"generator\". A generator must be installed before being able to use it. The generators listed in this document are automatically installed when the npm dependencies of this workspace have been installed.</p> <pre><code>yarn add -D &lt;generator&gt;\n</code></pre> <p>Create a new project:</p> <pre><code>nx g &lt;generator&gt;:&lt;project-type&gt; &lt;project&gt; [--dry-run]\n</code></pre> <p>The option <code>--dry-run</code> simulates the generation of the project and shows the location of the files that would be generated.</p> <p>Generators used in this workspace:</p> Project Type Generator Command Angular app <code>nx g @nx/angular:app &lt;project&gt;</code> React app <code>nx g @nrwl/react:app &lt;project&gt;</code> TypeScript CLI <code>nx generate @nx/js:app &lt;project&gt;</code> Angular lib <code>nx g @nx/angular:lib &lt;project&gt;</code> <p>Newly created projects are added to workspace.json.</p>"},{"location":"_archive/cheat-sheet/#create-an-angular-component","title":"Create an Angular component","text":"<pre><code>nx g @nx/angular:component &lt;component&gt; --project &lt;project&gt;\n</code></pre> <p>Example:</p> <p>Add a component named <code>header</code> to the library <code>web-ui</code>:</p> <pre><code>nx g @nx/angular:component header --project web-ui --dry-run\n\nCREATE libs/web/ui/src/lib/header/header.component.scss\nCREATE libs/web/ui/src/lib/header/header.component.html\nCREATE libs/web/ui/src/lib/header/header.component.spec.ts\nCREATE libs/web/ui/src/lib/header/header.component.ts\nUPDATE libs/web/ui/src/lib/web-ui.module.ts\n</code></pre>"},{"location":"_archive/cheat-sheet/#create-an-angular-service","title":"Create an Angular service","text":"<pre><code>nx g @nx/angular:service page-title --project web-data-access\n</code></pre> <p>Example:</p> <p>Add a service named <code>page-title</code> to the library <code>web-data-access</code>:</p> <pre><code>nx g @nx/angular:service page-title --project web-data-access --dry-run\n\nCREATE libs/web/data-access/src/lib/page-title.service.spec.ts\nCREATE libs/web/data-access/src/lib/page-title.service.ts\n</code></pre>"},{"location":"_archive/cheat-sheet/#nx","title":"Nx","text":"<p>Each project includes the file <code>project.json</code> that defines one or more \"targets\".</p> <p>Run a single target:</p> <pre><code>nx &lt;target&gt; &lt;project&gt;  // OR\nnx run &lt;project&gt;:&lt;target&gt;\n</code></pre> <p>Run a given target for multiple projects:</p> <pre><code>[nx run-many] --target=test --all\nnx run-many --target=test --all --parallel  // executes in parallel (default: 3)\nnx run-many --target=test --all --parallel=2\nnx run-many --target=test --projects=proj1,proj2\n</code></pre> <p>List the apps and libs that are affected by uncommitted changes.</p> <pre><code>nx affected:apps\nnx affected:libs\n</code></pre> <p>Run a given target for all the projects affected:</p> <pre><code>nx affected:&lt;target&gt;\nnx affected:&lt;target&gt; --parallel\n</code></pre>"},{"location":"_archive/cheat-sheet/#analyzing-visualizing-workspaces","title":"Analyzing &amp; Visualizing Workspaces","text":"<p>Explore the project dependency graph:</p> <pre><code>nx graph\n\n&gt;  NX   Affected criteria defaulted to --base=main --head=HEAD\n&gt;  NX   Project graph started at http://127.0.0.1:4211\n\nnx affected:graph  // select all the projects affected\n</code></pre>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/","title":"Collect challenge logs and system metrics","text":"<p>This document describes how to centralize and explore the logs and system metrics generated by a fleet of hosts (EC2 instances) and Docker containers. The instructions are provided in the context of monitoring hosts and containers during a scientific challenge organized by Sage Bionetworks.</p>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#objectives","title":"Objectives","text":"<p>The solution described here offers a single, user-friendly interface to monitor logs and visualize system metrics generated by a fleet of hosts and containers. This solution contributes to</p> <ul> <li>Enhanced security</li> <li>Quickly access to network usage (in/out).</li> <li> <p>Set alerts.</p> <ul> <li>E.g., send an email notification when unusual inbound and/or outbound network traffic occur.</li> </ul> </li> <li> <p>Improved stability</p> </li> <li>Quickly access system health information.</li> <li> <p>Set alerts.</p> <ul> <li>E.g., send an email notification when the filesystem of a host is almost filled to its   capacity, which can lead to a crash of the system. The alert enables an engineer to   preemptively increase the available storage space.</li> </ul> </li> <li> <p>Better engineer experience</p> </li> <li> <p>A single, user-friendly dashboard enables the engineer in charge of monitoring the system to     quickly access logs and system health information.</p> </li> <li> <p>Enhanced reporting</p> </li> <li>Collect and visualize information about how the system is used. This data can help to better     understand the needs of the users and better dimension the system to cut costs.</li> </ul> <p>In the context of the organization of a scientific challenge, the collected data aim to answer the following questions:</p> <ul> <li>Are all the EC2 instances up?</li> <li>Is an instance at risk of crashing because its storage capacity is nearly filled up?</li> <li>Are submissions using all the CPU cores available?</li> <li>Are submissions using the GPU cores available?</li> <li>Is a submission crashing due to a memory leak (memory usage, logs)?</li> <li>Is a submission generating too much data (logs, scratch/pre-processed/output files)</li> <li>What fraction of the uptime of an EC2 instance is used to process submissions?</li> <li>How much money could we have saved using on-demand EC2 instances?</li> </ul>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#architecture","title":"Architecture","text":"<p>The components of the stack are:</p> <ul> <li><code>challenge-elk</code>: EC2 instance that runs the ELK stack</li> <li><code>challenge-node-*</code>: EC2 instances that run Beat agents (Metricbeat, Filebeat).</li> </ul> <p>Note Instructions on how to deploy and use this monitoring solution are given below. The instructions are given in the context of monitoring a stack used to process submissions received during a scientific challenge. However, this solution can be used to monitor hosts and containers deployed for other applications.</p>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#cost-estimate","title":"Cost estimate","text":"<p>The only additional resource introduced by this architecture is the EC2 instance where the ELK stack is deployed. The instance must have at least 4 GB and 2 vCPUs, which is why a <code>t2.medium</code> is recommended. The storage capacity needed depends on the number of instances monitored, the size and frequency of the data collected. It is currently recommended to allocate 100 GB of storage (under evaluation).</p> <p>For example, here is a cost estimate for the recommended EC2 instance (valid on 2022-07-24).</p> <ul> <li>$0.0464 per On Demand Linux <code>t2.medium</code> Instance Hour</li> <li>$0.10 per GB-month of General Purpose SSD (gp2) provisioned storage - US East (Northern Virginia)</li> </ul> <p>Total: 30 * 24 * 0.0464 + 100 * 0.10 = $43.4/month</p>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#authors","title":"Authors","text":"<p>Please give credit to the following persons if you are using or building on top of this solution.</p> <ul> <li>Thomas Schaffter</li> <li>Verena Chung</li> </ul>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#contents","title":"Contents","text":"<ol> <li>Requirements</li> <li>Deploy the ELK Stack<ul> <li>Create the EC2 instance</li> <li>Connect to the instance</li> <li>SSM with SSH</li> <li>Prepare the instance</li> <li>Configure the ELK Stack</li> <li>Start the ELK Stack</li> <li>Connect to Kibana</li> </ul> </li> <li>Deploy Beat agents<ul> <li>Metricbeat</li> <li>Filebeat</li> <li>Set up Beat assets</li> </ul> </li> <li>Explore and visualize data in Kibana<ul> <li>Inventory</li> <li>Logs Stream</li> <li>Dashboards</li> <li>[Metricbeat System] Overview ECS</li> <li>Discover</li> </ul> </li> <li>Improvements and future activities</li> </ol>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#requirements","title":"Requirements","text":"<ul> <li>1 EC2 instance where the ELK Stack will be deployed.</li> <li>This instance requires the Docker Engine (see ELK Stack host requirements).</li> <li>N EC2 instances to monitor using Beat agents (Metricbeat, Filebeat).</li> </ul>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#deploy-the-elk-stack","title":"Deploy the ELK Stack","text":""},{"location":"_archive/collect-challenge-logs-and-system-metrics/#create-the-ec2-instance","title":"Create the EC2 instance","text":"<p>Create an EC2 instance in the AWS account <code>CnbAccount</code> with the following specifications.</p> <p>Note <code>CnbAccount</code> represents the AWS account of the Challenge &amp; Benchmarking group at Sage.</p> <ul> <li>Name and tags</li> <li>Name: <code>&lt;challenge name&gt;-elk</code> (e.g. <code>ptb-challenge-elk</code>)</li> <li> <p>Tags:</p> <ul> <li><code>Department</code>: <code>CNB</code></li> <li><code>Project</code>: <code>challenge</code> (selected from this   list)</li> <li><code>CostCenter</code>: select value from these   lists</li> </ul> </li> <li> <p>Application and OS Images (Amazon Machine Image)</p> </li> <li>Amazon Machine Image (AMI): <code>Ubuntu Server 22.04 LTS (HVM), SSD Volume Type</code></li> <li> <p>Architecture: <code>64-bit (x86)</code></p> </li> <li> <p>Instance type</p> </li> <li> <p>Instace type: <code>t2.medium</code>     &gt; Note     &gt; The instance needs at least 2 vCPUs and 4 GB of memory.</p> </li> <li> <p>Key pair</p> </li> <li> <p>Select your SSH key pair or create a new one.</p> </li> <li> <p>Network settings</p> </li> <li>Click on <code>Edit</code></li> <li>VPC: <code>vpc-0a70996f3e816e067</code></li> <li>Subnet: <code>subnet-01898b708714fa3b6</code></li> <li>Firewall<ul> <li>Select <code>Select existing security group</code>.</li> <li>Select <code>sg-0807a0e374542affd (cnbvpc-VpnSecurityGroup-JBXT9AUVDXCA)</code>.</li> </ul> </li> </ul> <p>Note These values will be different if you are creating the EC2 instance from an AWS account different from <code>CnbAccount</code>.</p> <ul> <li>Configure storage</li> <li>1x 100 GB gp2</li> </ul> <p>Once the instance has been created, configure it to use the following IAM:</p> <ul> <li>Go to <code>EC2</code> &gt; <code>Instances</code>.</li> <li>Select the ELK instance.</li> <li>Click on the button <code>Actions</code> &gt; <code>Security</code> &gt; <code>Modify IAM role</code>.</li> <li>Select the IAM role <code>AmazonSSMRoleForInstancesQuickSetup</code>.</li> </ul>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#connect-to-the-instance","title":"Connect to the instance","text":"<p>Use the AWS Systems Manager Agent (SSM Agent) to connect to the EC2 instance. If this is your first time ever connecting to an instance created by the CnbAccount AWS account, complete the following step first. Otherwise, skip to steps 2 and 3.</p> <ol> <li> <p>Create an <code>~/.aws/config</code> file if you do not already have one. Add the following:     <pre><code>[profile cnb]\nregion = us-east-1\nsso_start_url = https://d-906769aa66.awsapps.com/start\nsso_region = us-east-1\nsso_account_id = 216152803258\nsso_role_name = Administrator\noutput = json\n</code></pre>     This will create a named AWS profile called <code>cnb</code>.</p> </li> <li> <p>Before connecting to any <code>cnb</code> instances, first login to AWS SSO:     <pre><code>aws --profile cnb sso login\n</code></pre>    A browser window will pop up, asking for access from an application. Click <code>Allow</code>. You are now    authenticated for remote access for the next 8-10 hours. Re-login as necessary.</p> </li> <li> <p>Connect to the instance as <code>ubuntu</code>, passing the <code>Instance ID</code> to <code>--target</code>:     <pre><code>aws ssm start-session \\\n  --profile cnb \\\n  --document-name AWS-StartInteractiveCommand \\\n  --parameters command=\"sudo su - ubuntu\" \\\n  --target &lt;instance id&gt;\n</code></pre></p> </li> </ol>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#ssm-with-ssh","title":"SSM with SSH","text":"<p>Follow these instructions to connect to the instance via SSH using the command <code>ssh &lt;profile name&gt;</code>.</p> <ol> <li> <p>Add a new profile to the <code>~/.ssh/config</code> file.     <pre><code>Host &lt;challenge name&gt;-elk\n  HostName i-0fad4cb3e6543283e\n  User ubuntu\n  IdentityFile ~/.ssh/&lt;your pem file&gt;\n  ProxyCommand sh -c \"AWS_PROFILE=cnb aws ssm start-session --target %h --document-name AWS-StartSSHSession --parameters 'portNumber=%p'\"\n</code></pre></p> </li> <li> <p>Copy the public portion of your SSH key (on your local computer) to the instance\u2019s    <code>~/.ssh/authorizedkeys</code> file.</p> </li> <li> <p>Set the permission of the authorizedkeys file to 600.     <pre><code>chmod 600 ~/.ssh/authorizedkeys\n</code></pre></p> </li> <li> <p>Connect to the instance.     <pre><code>ssh &lt;challenge name&gt;-elk\n</code></pre></p> </li> </ol>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#prepare-the-instance","title":"Prepare the instance","text":"<ol> <li> <p>Start by updating the system packages on the instance. System packages should be regularly    updated for enhanced security. On Ubuntu,     <pre><code>sudo apt update\nsudo apt upgrade -y\n</code></pre></p> </li> <li> <p>Install the Docker Engine.</p> <ul> <li>Enable the non-root user to execute Docker commands.</li> <li>Enable the Docker Engine to start at startup.   <pre><code>sudo systemctl enable docker\n</code></pre></li> </ul> </li> <li> <p>We will use the hostname of the EC2 instances to filter logs and metrics in Kibana. Therefore, it    is recommended to use short and descriptive hostnames. To update the hostname of an EC2 instance:</p> <ul> <li>Open the file <code>/etc/hostname</code>.</li> <li>Set the hostname to <code>&lt;challenge name&gt;-elk</code>. For example, <code>ptb-challenge-elk</code> for the instance   running the ELK stack for the Preterm Birth Prediction DREAM Challenge, and   <code>ptb-challenge-node-&lt;uuid&gt;</code> for instances that process challenge submissions.</li> </ul> </li> </ol>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#configure-the-elk-stack","title":"Configure the ELK Stack","text":"<ol> <li> <p>Clone the GH repository of the ELK stack.     <pre><code>git clone --depth 1 https://github.com/Sage-Bionetworks/docker-elk.git\n</code></pre></p> </li> <li> <p>Configure the ELK stack.</p> <ul> <li>Disable paid features.</li> <li>Set new passwords in <code>.env</code>.</li> </ul> <p>Note Create new passwords using the password generator that should come with your favorite password manager.</p> <p>Save the new passwords in Sage password manager.</p> </li> </ol>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#start-the-elk-stack","title":"Start the ELK Stack","text":"<p>Start the ELK stack services using Docker Compose:</p> <pre><code>docker compose up -d\n</code></pre> <p>Note The stack can be stopped with <code>docker compose stop</code> and restarted with <code>docker compose start</code>.</p>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#connect-to-kibana","title":"Connect to Kibana","text":"<p>Kibana (the \"K\" in ELK) is a free and open user interface that lets you visualize your Elasticsearch data and navigate the Elastic Stack.</p> <p>To access Kibana, start by forwarding the Kibana port (5601) to your localhost using AWS SSM.</p> <pre><code>$ AWS_PROFILE=cnb aws ssm start-session --target &lt;instance id&gt; --document-name AWS-StartPortForwardingSession --parameters '{\"portNumber\":[\"5601\"], \"localPortNumber\":[\"5601\"]}'\n\nStarting session with SessionId: ...\nPort 5601 opened for sessionId ...\nWaiting for connections...\n</code></pre> <p>Note For developers of the OpenChallenges, VS Code is already forwarding the port 5601 to localhost when running the project dev container. Either make sure that the dev container is not running when accessing Kibana or forward the Kibana port to another port on localhost, e.g. with <code>--parameters '{\"portNumber\":[\"5601\"], \"localPortNumber\":[\"56010\"]}'</code> (notice the trailing <code>0</code>).</p> <p>Give Kibana about 2-3 minutes to initialize after having started it, then access the Kibana web UI by opening <code>http://localhost:5601</code> in a web browser and use the following (default) credentials to log in:</p> <ul> <li>user: <code>elastic</code></li> <li>password: <code>&lt;elastic password&gt;</code></li> </ul> <p>Congrats! You have successfully logged into Kibana. You should be welcomed with a dialog that invites you to install integration components. You can skip this step.</p>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#deploy-beat-agents","title":"Deploy Beat agents","text":""},{"location":"_archive/collect-challenge-logs-and-system-metrics/#metricbeat","title":"Metricbeat","text":"<p>Metricbeat is a Elastic Beat agent that we will deploy on all the EC2 instances, including the instance that runs the ELK stack, to monitor the following metrics: CPU usage, memory usage, filesystem usage, and network usage. Metricbeat will send this information at the host and Docker container levels.</p> <ol> <li>Ssh to an EC2 instance.</li> <li> <p>Install Metricbeat (select the <code>DEB</code> tab).     &gt; Note The version of Metricbeat must match the version of the ELK stack. The version of the     &gt; ELK stack is specified in the configuration file <code>.env</code> of the ELK stack.</p> </li> <li> <p>Enable the Metricbeat <code>docker</code> module.     <pre><code>sudo metricbeat modules enable docker\n</code></pre></p> </li> <li> <p>Check that the following modules are enable: <code>system</code>, <code>docker</code>.     <pre><code>sudo metricbeat modules list\n</code></pre></p> </li> <li> <p>Specify the IP address and credentials that Metricbeat must use to connect to the EKL stack.</p> <ul> <li>Open the Metricbeat configuration file <code>/etc/metricbeat/metricbeat.yml</code>.</li> <li>Update the configuration for the section <code>output.elasticsearch</code>.   <pre><code>output.elasticsearch:\n  hosts: [\"&lt;elasticsearch ip&gt;:9200\"]\n  username: \"elastic\"\n  password: \"&lt;elastic password&gt;\"\n</code></pre></li> </ul> </li> <li> <p>Update the metrics that the <code>docker</code> module should capture.</p> <ul> <li>Open the <code>docker</code> module configuration file <code>/etc/metricbeat/modules.d/docker.yml</code>.</li> <li>Use the following configuration:   <pre><code>- module: docker\n  metricsets:\n    - container\n    - cpu\n    - diskio\n    - event\n    - healthcheck\n    - image\n    - info\n    - memory\n    - network\n  #  - network_summary\n  period: 10s\n  hosts: [\"unix:///var/run/docker.sock\"]\n</code></pre></li> </ul> </li> <li> <p>Enable Metricbeat to start at startup.     <pre><code>sudo systemctl enable metricbeat\n</code></pre></p> </li> <li> <p>Start Metricbeat.     <pre><code>sudo systemctl start metricbeat\n</code></pre></p> </li> <li> <p>Check that Metricbeat has successfully started.     <pre><code>sudo systemctl status metricbeat\n</code></pre>     Look at the logs for any error messages. If Metricbeat failed to start, try restarting it with     <code>sudo systemctl restart metricbeat</code>.</p> </li> </ol> <p>Metricbeat should now be sending data to the ELK Stack!</p>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#filebeat","title":"Filebeat","text":"<p>Filebeat is a Elastic Beat agent that we will deploy on all the EC2 instances, including the instance that runs the ELK stack, to monitor system log files.</p> <ol> <li>Ssh to an EC2 instance.</li> <li> <p>Install Filebeat (select the <code>DEB</code> tab).     &gt; Note The version of Filebeat must match the version of the ELK stack. The version of the     &gt; ELK stack is specified in the configuration file <code>.env</code> of the ELK stack.</p> </li> <li> <p>Enable the Filebeat <code>system</code> module.     <pre><code>sudo filebeat modules enable system\n</code></pre></p> </li> <li> <p>Check that the following modules are enable: <code>system</code>.     <pre><code>sudo filebeat modules list\n</code></pre></p> </li> <li> <p>Specify the IP address and credentials that Filebeat must use to connect to the EKL stack.</p> </li> <li>Open the Filebeat configuration file <code>/etc/filebeat/filebeat.yml</code>.</li> <li> <p>Update the configuration for the section <code>output.elasticsearch</code>.       <pre><code>output.elasticsearch:\n  hosts: [\"&lt;elasticsearch ip&gt;:9200\"]\n  username: \"elastic\"\n  password: \"&lt;elastic password&gt;\"\n</code></pre></p> </li> <li> <p>Update the metrics that the <code>system</code> module should capture.</p> <ul> <li>Open the <code>system</code> module configuration file <code>/etc/filebeat/modules.d/system.yml</code>.</li> <li>Use the following configuration:   <pre><code>- module: system\n  syslog:\n    enabled: true\n</code></pre></li> </ul> </li> <li> <p>Enable Filebeat to start at startup.     <pre><code>sudo systemctl enable filebeat\n</code></pre></p> </li> <li> <p>Start Filebeat.     <pre><code>sudo systemctl start filebeat\n</code></pre></p> </li> <li> <p>Check that Filebeat has successfully started.     <pre><code>sudo systemctl status filebeat\n</code></pre>     &gt; Note Look at the logs for any error messages. If Filebeat failed to start, try restarting     &gt; it with <code>sudo systemctl restart filebeat</code>.</p> </li> </ol> <p>Filebeat should now be sending data to the ELK Stack!</p>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#set-up-beat-assets","title":"Set up Beat assets","text":"<p>Beats such as Metricbeat and Filebeat comes with predefined assets for parsing, indexing, and visualizing your data. To load these assets, run the following commands from the EC2 instance that runs the ELK stack.</p> <pre><code>sudo metricbeat setup -e --dashboards\nsudo filebeat setup -e --dashboards\n</code></pre> <p>These commands may take 1-2 minutes to complete.</p>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#explore-and-visualize-data-in-kibana","title":"Explore and visualize data in Kibana","text":"<p>After logging in Kibana, try to access the following sections to start exploring and monitoring the data sent to the ELK stack.</p>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#inventory","title":"Inventory","text":"<p>This page shows the compute resources used by all the hosts (EC2 instances) and Docker containers. To open the Inventory,</p> <ol> <li>Click on the top-left menu button.</li> <li>Click on <code>Observability</code> &gt; <code>Metrics</code>.</li> </ol> <p>Each host is represented by a tile in the Inventory. Click on one of the hosts to quickly access information about CPU, memory and network usage. The same dialog gives access to the following information:</p> <ul> <li>Tab <code>Logs</code>: access the logs generated by the host (sent by Filebeat).</li> <li>Tab <code>Processes</code>: see the list of processes running on the host.</li> <li>Tab <code>Metadata</code>: see host metadata such as OS distrubution name and version, architecture, etc.</li> </ul> <p></p> <p>To display similar information for the running Docker containers, set the value of the menu <code>Show</code> to <code>Docker Containers</code>. The tiles shown now represent the Docker containers running across all the hosts. Use the search bar to filter hosts and containers. For example, enter <code>host.hostname: ptb-challenge-gpu</code> to show only the containers running on the host <code>ptb-challenge-gpu</code>.</p>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#logs-stream","title":"Logs Stream","text":"<p>This page shows the logs generated by all the hosts and sent by Filebeat to the ELK stack. To open the Logs Stream,</p> <ol> <li>Click on the top-left menu button.</li> <li>Click on <code>Observability</code> &gt; <code>Logs</code>.</li> </ol> <p></p>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#dashboards","title":"Dashboards","text":"<p>Earlier, we initialized the ELK Stack with Beats assets, which include several dashboards that we can use to monitor the fleet of hosts and containers. Here is a list of dashboards that are useful for monitoring the challenge hosts and containers.</p> <p>To access the complete list of dashboards,</p> <ol> <li>Click on the top-left menu button.</li> <li>Click on <code>Analytics</code> &gt; <code>Dashboard</code>.</li> </ol>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#metricbeat-system-overview-ecs","title":"[Metricbeat System] Overview ECS","text":"<p>This dashboard provides an overview of system metrics such as CPU, memory, network and filesystem usage. By default, the dashboard displays information aggregated across all the hosts and Docker containers. A filter can be specified to display data for a single host. For example, by specifying the filter <code>host.name:\"&lt;instance hostname&gt;\"</code>.</p> <p></p>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#discover","title":"Discover","text":"<p>The Discover page enables us to quickly explore all the data indexed in the ELK stack.</p> <p>To access the Discover page,</p> <ol> <li>Click on the top-left menu button.</li> <li>Click on <code>Analytics</code> &gt; <code>Discover</code>.</li> </ol> <p>For example, we want to visualize the evolution of the available filesystem of all the hosts. This information is important when troubleshooting the crash of an host as it is possible that the crash occurred because the filesystem was filled up to its capacity.</p> <p>On the Discovery page,</p> <ol> <li>Click on the top-left button included in the Discovery page, select the index <code>metricbeat-*</code>.</li> <li>In the <code>Search field names</code> input, enter <code>system.filesystem.available</code>.</li> <li> <p>In the list of available fields, click on <code>system.filesystem.available</code>, then click on the    button <code>Visualize</code>.</p> </li> <li> <p>In the right panel, set the following properties:</p> <ul> <li>Horizontal axis: <code>@timestamp</code></li> <li>Vertical axis: <code>Median of system.filesystem.available</code></li> <li>Break down by: <code>host.name</code></li> </ul> </li> <li> <p>Generate a line plot by selecting <code>Line</code> after clicking on one of the menu button above the plot.</p> </li> </ol> <p>You should now be able to see a view similar to the one shown below.</p> <p></p> <p>From there, the following actions are available:</p> <ul> <li>Download the plot data in CSV format Click by clicking on the button <code>Download as CSV</code>.</li> <li>Save the plot to access it later by clicking on the button <code>Save</code>.</li> </ul>"},{"location":"_archive/collect-challenge-logs-and-system-metrics/#improvements-and-future-activities","title":"Improvements and future activities","text":"<ul> <li>Configure the ELK stack to use https connections.</li> <li>when the user connects to Kibana</li> <li>when the Beat agents pushes data to Elasticsearch/Logstash</li> <li>Deploy the Beat agents using Docker.</li> <li>Configure the <code>aws</code> module of Metricbeat to collect CloudWatch data, including billing   information.</li> <li>Create a custom dashboard in Kibana that shows all the information relevant.</li> <li>Collect logs generated by the Challenge Orchestrator.</li> <li>Collect GPU usage.<ul> <li>The Beat Nvidiagpubeat only supports ELK v6 and v7. We are currently using ELK v8.3.0.</li> </ul> </li> <li>Develop a custom Beat to collect information specific to our projects. For instance, a Beat that   sends information about the number of submission in a queue to the ELK stack.<ul> <li>See Community Beats.</li> </ul> </li> </ul>"},{"location":"_archive/coverage/","title":"Coverage","text":""},{"location":"_archive/coverage/#code-coverage","title":"Code Coverage","text":""},{"location":"_archive/coverage/#generating-coverage-manually","title":"Generating coverage manually","text":"<p>Create a file <code>.coveralls.yml</code> which at minimum should contain this one line:</p> <pre><code>repo_token: \"coveralls-token-for-your-repo\"\n</code></pre> <p>Generate the coverage report for a project.</p> <pre><code>nx test openchallenges-about\n</code></pre> <p>Push a coverage report to Coveralls.</p> <pre><code>npx coveralls &lt; coverage/libs/openchallenges/about/lcov.info\n</code></pre>"},{"location":"_archive/create-a-new-angular-component/","title":"Create a new angular component","text":"<p>This doc describes how to create a new library + component in the OpenChallenges app, though the steps can be applied to any app in this project. This doc will also include information on where/how to copy-paste code from the [Figma-to-code export] into the app (starting at [Step 5]).</p>"},{"location":"_archive/create-a-new-angular-component/#1-create-a-new-angular-library","title":"1. Create a new Angular library","text":"<p>To create a UI library within <code>openchallenges</code>, run:</p> <pre><code>nx g @nx/angular:lib &lt;new library name&gt; --directory openchallenges\n</code></pre> <p>(Optional but recommended) Use <code>--dryrun</code> to first see what and where the entities will be created; this will help visualize and validate the intended directory structure, e.g.</p> <pre><code>$ nx g @nx/angular:lib awesome-lib --directory openchallenges --dry-run\n\n&gt;  NX  Generating @nx/angular:library\n\n...\nUPDATE workspace.json\nCREATE libs/openchallenges/awesome-lib/README.md\nCREATE libs/openchallenges/awesome-lib/tsconfig.lib.json\nCREATE libs/openchallenges/awesome-lib/tsconfig.spec.json\nCREATE libs/openchallenges/awesome-lib/src/index.ts\nCREATE libs/openchallenges/awesome-lib/src/lib/openchallenges-awesome-lib.module.ts\nCREATE libs/openchallenges/awesome-lib/tsconfig.json\nCREATE libs/openchallenges/awesome-lib/project.json\nUPDATE tsconfig.base.json\nCREATE libs/openchallenges/awesome-lib/jest.config.ts\nCREATE libs/openchallenges/awesome-lib/src/test-setup.ts\nCREATE libs/openchallenges/awesome-lib/.eslintrc.json\n\nNOTE: The \"dryRun\" flag means no changes were made.\n</code></pre> <p>Due to how the OpenChallenges app is currently structured, some additional steps are required:</p> <ol> <li> <p>Remove <code>openchallenges-</code> from the filename of the module TypeScript in <code>src/lib/</code>, e.g.</p> <p><code>openchallenges-awesome-lib.module.ts</code> \u2192 <code>awesome-lib.module.ts</code></p> </li> <li> <p>Simiarly, in <code>src/index.ts</code>, remove <code>openchallenges-</code> from the import filepath.</p> </li> <li>In the library module (<code>&lt;new library name&gt;.module.ts</code>), remove <code>ChallengeRegistry</code> from     the class name, e.g.     <code>export class ChallengeRegistryAwesomeLibModule {}</code> \u2192 <code>export class AwesomeLibModule {}</code></li> </ol> <p>Note: still have questions about libraries? See [Libraries] for more details.</p>"},{"location":"_archive/create-a-new-angular-component/#2-create-a-new-angular-component","title":"2. Create a new Angular component","text":"<p>To create the component, use:</p> <pre><code>nx g @nx/angular:component &lt;new component name&gt; --project &lt;project-name&gt;\n</code></pre> <p>where <code>&lt;project name&gt;</code> is the name of the project defined in <code>project.json</code> of the newly-created Angular library.</p> <p>For example, to create an Angular component for the <code>awesome-lib</code> library, the project name would be <code>openchallenges-awesome-lib</code>, as defined in <code>libs/openchallenges/awesome-lib/project.json</code>:</p> <pre><code>{\n  \"name\": \"openchallenges-awesome-lib\",\n  \"$schema\": \"../../../node_modules/nx/schemas/project-schema.json\",\n  \"projectType\": \"library\",\n  ...\n}\n</code></pre> <p>The resulting command would then be:</p> <pre><code>$ nx g @nx/angular:component awesome-lib --project openchallenges-awesome-lib --dry-run\n\n&gt;  NX  Generating @nx/angular:component\n\nCREATE libs/openchallenges/awesome-lib/src/lib/awesome-lib/awesome-lib.component.scss\nCREATE libs/openchallenges/awesome-lib/src/lib/awesome-lib/awesome-lib.component.html\nCREATE libs/openchallenges/awesome-lib/src/lib/awesome-lib/awesome-lib.component.spec.ts\nCREATE libs/openchallenges/awesome-lib/src/lib/awesome-lib/awesome-lib.component.ts\nUPDATE libs/openchallenges/awesome-lib/src/lib/awesome-lib.module.ts\n\nNOTE: The \"dryRun\" flag means no changes were made.\n</code></pre> <p>Note: notice that the command above is using <code>dry-run</code>. Again, this is just to ensure that the new entities will be created in the right folder. If everything looks correct, remove the flag to actually create the new component.</p> <p>To directly create the files into the parent folder, use <code>--flat</code> in the command:</p> <pre><code>$ nx g @nx/angular:component awesome-lib --project openchallenges-awesome-lib --flat -dry-run\n\n&gt;  NX  Generating @nx/angular:component\n\nCREATE libs/openchallenges/awesome-lib/src/lib/awesome-lib.component.scss\nCREATE libs/openchallenges/awesome-lib/src/lib/awesome-lib.component.html\nCREATE libs/openchallenges/awesome-lib/src/lib/awesome-lib.component.spec.ts\nCREATE libs/openchallenges/awesome-lib/src/lib/awesome-lib.component.ts\nUPDATE libs/openchallenges/awesome-lib/src/lib/awesome-lib.module.ts\n\nNOTE: The \"dryRun\" flag means no changes were made.\n</code></pre> <p>Notice how the component files would be created directly in <code>awesome-lib/src/lib/</code>, compared with <code>awesome-lib/src/lib/awesome-lib/</code> when <code>--flat</code> is not used.</p> <p>Before moving on, some additional edits are required:</p> <ol> <li>Remove the <code>&lt;new component name&gt;.component.spec.ts</code> file -- it is not needed.</li> <li> <p>In the <code>&lt;new component name&gt;.component.ts</code> file:</p> <ul> <li>Remove <code>OnInit</code> from the import and all instances of it from the class</li> <li>Import <code>ConfigService</code> from <code>@sagebionetworks/openchallenges/config</code></li> <li>Pass <code>configService</code> into the constructor as <code>private readonly</code></li> </ul> <p>The final result should look something like this:</p> <pre><code>import { Component } from '@angular/core';\nimport { ConfigService } from '@sagebionetworks/openchallenges/config';\n\n@Component({\n  selector: 'sagebionetworks-awesome-lib',\n  templateUrl: './awesome-lib.component.html',\n  styleUrls: ['./awesome-lib.component.scss'],\n})\nexport class AwesomeLibComponent {\n  constructor(private readonly configService: ConfigService) {}\n}\n</code></pre> </li> <li> <p>Revisit the library module (<code>&lt;library name&gt;.module.ts</code>) and import the UI and     routing modules:</p> <pre><code>```ts\n...\nimport { RouterModule, Routes } from '@angular/router';\n\nconst routes: Routes = [{ path: '', component: &lt;component&gt; }];\n\n@NgModule({\n  imports: [CommonModule, RouterModule.forChild(routes)],\n  ...\n```\n\nwhere `&lt;component&gt;` is the newly-created Angular component. You will also need\nto export the newly-created Angular component, e.g.\n\n```ts\n@NgModule({\n  ...\n  exports: [AwesomeLibComponent],\n})\n```\n\nThe final result should look something like this:\n\n  ```ts\n  import { NgModule } from '@angular/core';\n  import { CommonModule } from '@angular/common';\n  import { RouterModule, Routes } from '@angular/router';\n  import { AwesomeLibComponent } from './awesome-lib.component';\n\n  const routes: Routes = [{ path: '', component: AwesomeLibComponent }];\n\n  @NgModule({\n    imports: [CommonModule, RouterModule.forChild(routes)],\n    declarations: [AwesomeLibComponent],\n    exports: [AwesomeLibComponent],\n  })\n  export class AwesomeLibModule {}\n  ```\n</code></pre> </li> </ol>"},{"location":"_archive/create-a-new-angular-component/#3-add-routing","title":"3. Add routing","text":"<p>In <code>apps/openchallenges/src/app/app-routing.module.ts</code>, add a router for the new component, e.g.</p> <pre><code>  {\n    path: &lt;new path name&gt;,\n    loadChildren: () =&gt;\n      import('&lt;index&gt;').then(\n        (m) =&gt; m.&lt;module&gt;\n      ),\n  },\n</code></pre> <p>where <code>&lt;index&gt;</code> is the path defined <code>tsconfig.base.json</code>. For example, the base for AwesomeLib is:</p> <pre><code>{\n  ...\n  \"paths\": {\n    \"@sagebionetworks/openchallenges/awesome-lib\": [\n      \"libs/openchallenges/awesome-lib/src/index.ts\"\n    ],\n    ...\n  }\n}\n</code></pre> <p>So, the resulting router would look something like this:</p> <pre><code>  {\n    path: 'awesome-path',\n    loadChildren: () =&gt;\n      import('@sagebionetworks/openchallenges/awesome-lib').then(\n        (m) =&gt; m.AwesomeLibModule\n      ),\n  },\n</code></pre> <p>\u26a0\ufe0f IMPORTANT: we follow [Angular's standards for routing order], that is:</p> <p>List routes with a static path first, followed by an empty path route, which matches the default route. The wildcard route comes last because it matches every URL and the Router selects it only if no other routes match first.</p> <p>Please adhere to this recommended order when adding a new route.</p>"},{"location":"_archive/create-a-new-angular-component/#4-time-to-test","title":"4. Time to test! \u2615","text":"<p>If you haven't already, start a local server to test the newly-created component:</p> <pre><code>nx serve openchallenges\n</code></pre> <p>If everything is setup correctly, <code>http://localhost:4200/&lt;new path name&gt;</code> will open a web page that displays something like this:</p> <pre><code>&lt;component name&gt; works!\n</code></pre>"},{"location":"_archive/create-a-new-angular-component/#5-import-code-from-the-figma-to-code-export","title":"5. Import code from the Figma-to-Code export","text":""},{"location":"_archive/create-a-new-angular-component/#angular-export","title":"Angular export","text":"<p>If the Figma-to-code export was downloaded as Angular, the directory structure should be comparative to our current app structure, that is:</p> <pre><code>&lt;project name&gt;-angular\n\u251c\u2500\u2500 angular.json\n\u251c\u2500\u2500 browserslist\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 app\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 app.component.css\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 app.component.html\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 app.component.ts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 app.module.ts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 components\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 components.module.ts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 pages\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 *\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 *.component.css\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 *.component.html\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 *.component.ts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 *.module.ts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 **\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0         \u251c\u2500\u2500 **.component.css\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0         \u251c\u2500\u2500 **.component.html\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0         \u251c\u2500\u2500 **.component.ts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0         \u2514\u2500\u2500 **.module.ts\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 environments\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 environment.prod.ts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 environment.ts\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 index.html\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 main.ts\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 polyfills.ts\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 styles.css\n\u251c\u2500\u2500 tsconfig.app.json\n\u251c\u2500\u2500 tsconfig.json\n\u2514\u2500\u2500 tslint.json\n</code></pre> <p>Locate the HTML and CSS files within <code>src/app/pages/</code>, then copy-paste the code as needed. Alternatively, you can move the files into the app, then re-direct the paths in <code>*.component.ts</code> so that it uses these files:</p> <pre><code>@Component({\n  selector: 'openchallenges-team',\n  templateUrl: './&lt;new HTML file&gt;',\n  styleUrls: ['./&lt;new CSS/SCSS file&gt;'],\n})\n</code></pre>"},{"location":"_archive/create-a-new-angular-component/#html-export","title":"HTML export","text":"<p>If the Figma-to-code export was downloaded as HTML, the directory structure will be very simple:</p> <pre><code>&lt;project name&gt;-html\n\u251c\u2500\u2500 *.css\n\u251c\u2500\u2500 *.html\n\u251c\u2500\u2500 **.css\n\u251c\u2500\u2500 **.html\n\u251c\u2500\u2500 package.json\n\u2514\u2500\u2500 style.css\n</code></pre> <p>Copy-paste the HTML and CSS as needed, or move the files into the app then re-direct the paths in <code>*.component.ts</code>.</p>"},{"location":"_archive/create-a-new-angular-component/#6-update-themes","title":"6. Update themes","text":"<p>Once the exported styles files are copy-pasted to the app, some additional steps are required to configurate the themes of exported pages. Take awesome-lib as an example:</p> <pre><code>\u251c\u2500\u2500 awesome-lib\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 lib\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502   \u251c\u2500\u2500 awesome-lib.component.css\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502   \u251c\u2500\u2500 awesome-lib.component.html\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502   \u251c\u2500\u2500 awesome-lib.component.ts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502   \u251c\u2500\u2500 awesome-lib.module.ts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502   \u2514\u2500\u2500 sub-awesome-lib\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502       \u251c\u2500\u2500 sub-awesome-lib.component.css\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502       \u251c\u2500\u2500 sub-awesome-lib.component.html\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502       \u251c\u2500\u2500 sub-awesome-lib.component.ts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502       \u2514\u2500\u2500 sub-awesome-lib.module.ts\n...\n</code></pre> <ol> <li>Create theme files <code>_&lt;component-name&gt;-theme.scss</code> in each component, i.e. <code>libs/openchallenges/awesome-lib/_awesome-lib-theme.scss</code> and <code>libs/openchallenges/awesome-lib/src/lib/sub-awesome-lib/_sub-awesome-lib-theme.css</code> (repeat the step for each sub-component if any). Copy-paste below essential codes into all <code>_&lt;component-name&gt;-theme.scss</code> files:</li> </ol> <pre><code>@use 'sass:map';\n@use '@angular/material' as mat;\n\n@mixin color($theme) {\n  $config: mat.get-color-config($theme);\n  $primary: map.get($config, 'primary');\n  $accent: map.get($config, 'accent');\n  $warn: map.get($config, 'warn');\n  $figma: map.get($config, 'figma');\n}\n\n@mixin typography($theme) {\n}\n\n@mixin theme($theme) {\n  $color-config: mat.get-color-config($theme);\n  @if $color-config != null {\n    @include color($theme);\n  }\n\n  $typography-config: mat.get-typography-config($theme);\n  @if $typography-config != null {\n    @include typography($theme);\n  }\n}\n</code></pre> <ol> <li>Create <code>awesome-lib/src/_lib_themes.scss</code> and import all the themes of components:</li> </ol> <pre><code>@use './lib/awesome-lib-theme' as awesome-lib;\n@use './lib/sub-awesome-lib/sub-awesome-lib-theme' as sub-awesome-lib;\n@mixin theme($theme) {\n  @include awesome-lib.theme($theme);\n  @include sub-awesome-lib.theme($theme);\n}\n</code></pre> <ol> <li>Load the themes of awesome-lib library in <code>libs/openchallenges/themes/src/_index.scss</code> with below snippet:</li> </ol> <pre><code>@use 'libs/openchallenges/awesome-lib/src/lib-theme' as openchallenges-awesome-lib;\n@mixin theme($theme) {\n  @include openchallenges-awesome-lib.theme($theme);\n}\n</code></pre> <p>At this point, all theme files have been generated:</p> <pre><code>\u251c\u2500\u2500 awesome-lib\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 _lib-theme.scss\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 lib\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502   \u251c\u2500\u2500 _awesome-lib-theme.scss\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502   \u251c\u2500\u2500 awesome-lib.component.css\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502   \u251c\u2500\u2500 awesome-lib.component.html\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502   \u251c\u2500\u2500 awesome-lib.component.ts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502   \u251c\u2500\u2500 awesome-lib.module.ts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502   \u2514\u2500\u2500 sub-awesome-lib\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502       \u251c\u2500\u2500 _sub-awesome-lib-theme.css\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502       \u251c\u2500\u2500 sub-awesome-lib.component.css\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502       \u251c\u2500\u2500 sub-awesome-lib.component.html\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502       \u251c\u2500\u2500 sub-awesome-lib.component.ts\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502       \u2514\u2500\u2500 sub-awesome-lib.module.ts\n...\n</code></pre> <ol> <li> <p>In each component including sub-components, move all the colors and fonts from <code>&lt;component-name&gt;.component.scss</code> to <code>_&lt;component-name&gt;-themes.scss</code>.</p> </li> <li> <p>Now, the themes of new exported page has been configurated. However, some manually fine-tunes will still require to make page look like what figma's design. It's recommended to adjust the styles with the app's local server</p> </li> </ol> <pre><code>nx serve openchallenges\n</code></pre> <p>Most palettes used in the figma has been already configured in the app and defined in <code>libs/themes/src/_palettes.scss</code>. The palettes can be always retrieved via <code>map.get(&lt;theme-object-name&gt;, &lt;color-variable-name&gt;)</code>, i.e. <code>map.get($figma, dl-color-default-hover1)</code>. It's similar with the constant variables defined in <code>libs/styles/src/lib/_constants.scss</code>, i.e. <code>border-radius: constants.$dl-radius-radius-radius16;</code></p> <p>NoteAll color/font styles needs to be defined in <code>_&lt;component-name&gt;-theme.scss</code>.</p>"},{"location":"_archive/devcontainer/","title":"Devcontainer","text":"<p>This document describes how to configure and develop in the dev container specified by this repository. The goal is to provide developers with the same development environment that is mainly isolated from their host. This method promotes reproducibility and remove the need to install dependencies on the host such as Node.js or Python. For additional information on VS Code development containers, see Developing inside a Container.</p>"},{"location":"_archive/devcontainer/#requirements","title":"Requirements","text":"<ul> <li>Docker</li> <li>VS Code and the extension Remote - Containers</li> </ul>"},{"location":"_archive/devcontainer/#quick-start","title":"Quick Start","text":"<p>Open the workspace folder in VS Code after cloning it. VS Code should invite you to open the folder in the dev container specified by this repository. Alternatively:</p> <ul> <li>Press <code>F1</code> or Command+Shift+P (macOS) or   Ctrl+Shift+P (Windows) or click on <code>Help</code> &gt; <code>Show All Commands</code></li> <li>Enter <code>Remote-Containers: Open Folder in Container...</code></li> </ul> <p>That's it! VS Code should now have open the workspace folder in the dev container as indicated by the following green button displayed in the bottom-left corner of VS Code.</p> <p></p> <p>To reopen the workspace folder locally, click on the above green button and select <code>Reopen Folder Locally</code> or <code>Reopen Folder in WSL</code> when developing on Windows with WSL.</p>"},{"location":"_archive/devcontainer/#sharing-git-credentials-with-the-container","title":"Sharing Git credentials with the container","text":"<p>To run <code>git</code> commands that require authentication inside the dev container, please follow the instructions described in Sharing Git credentials with your container.</p> <p>If this repository has been closed using an SSH key, follow the instructions to share your host SSH keys with the dev container. The command below should list the same keys when executed on the host and inside the container.</p> <pre><code>ssh-add -l\n</code></pre> <p>Signing commits requires a GPG key. Follow the above instructions to share the host GPG keys with the dev container. The command below should now list the same keys when executed on the host and inside the container.</p> <pre><code>gpg --list-keys\n</code></pre>"},{"location":"_archive/developing-in-python/","title":"Developing in Python","text":""},{"location":"_archive/developing-in-python/#devcontainer-python-version","title":"Devcontainer Python version","text":"<p>The devcontainer used to contribute to this monorepo comes with one Python environment. The version of Python provided by this environment is as of May 19, 2023:</p> <pre><code>$ python --version\nPython 3.9.2\n</code></pre>"},{"location":"_archive/developing-in-python/#managing-the-python-environment-of-a-project","title":"Managing the Python environment of a project","text":"<p>By default, creating a new Python project in this monorepo with Poetry will use the Python version provided by the devcontainer. However, for various reasons, this Python version may not be compatible with the Python requirement of a given project.</p> <p>Let's take the project <code>schematic-api</code> as an example. The dependencies of this project are managed with Poetry. The project is currently configured to use Python 3.9.2. However, we now need to update the version of Python used by this project to 3.11.0 to solve a recent issue.</p> <p>First, we need to move to the project folder:</p> <pre><code>mv apps/schematic/api\n</code></pre> <p>Install the Python env <code>3.11.0</code> with <code>pyenv</code>:</p> <pre><code>pyenv install 3.11.0\n</code></pre> <p>Activate the new environment:</p> <pre><code>pyenv local 3.11.0\n</code></pre> <p>Check that the new env is active:</p> <pre><code>$ pyenv versions\n  system\n* 3.11.0 (set by /workspaces/sage-monorepo/apps/schematic/api/.python-version)\n</code></pre> <p>Update the Python version specified in the project files <code>pyproject.toml</code>:</p> <pre><code>poetry env use 3.11.0\n</code></pre> <p>Update the Python version specified in the lock file:</p> <pre><code>poetry lock --no-update\n</code></pre> <p>Build the project with the new Python env:</p> <pre><code>nx build schematic-api\n</code></pre>"},{"location":"_archive/enable-sso-with-keycloak/","title":"Enable SSO with Keycloak","text":"<ul> <li>Enable Google SSO</li> <li>Create a Google Application</li> <li>Create a Google identify provider in Keycloak</li> <li>Log in to the OpenChallenges with a Google account</li> <li>Notes</li> </ul>"},{"location":"_archive/enable-sso-with-keycloak/#enable-google-sso","title":"Enable Google SSO","text":""},{"location":"_archive/enable-sso-with-keycloak/#create-a-google-application","title":"Create a Google Application","text":"<ol> <li>Head to the Google Cloud Console, login with your (Sage) Google Account.</li> <li>Click on the dropdown near the Google Cloud logo.</li> <li>Click on <code>New Project</code>.</li> <li>Enter the information about the project.<ul> <li>Project name: <code>openchallenges-keycloak-google</code></li> <li>Organization: <code>sagebase.org</code></li> <li>Location: <code>sagebase.org</code></li> </ul> </li> <li>Click on <code>Create</code>.</li> <li>Select the new project by clicking on the dropdown near the Google Cloud logo.</li> <li>Click on <code>Credentials</code> in the left menu.</li> <li>Click on <code>Configure Consent Screen</code>.</li> <li>Enter the OAuth consent screen information.<ul> <li>User type: <code>Internal</code> (suitable for testing)</li> </ul> </li> <li>Click on <code>Create</code>.</li> <li>Enter the App information.<ul> <li>App name: <code>Challenge Keycloak Test App</code></li> <li>User support email: <code>&lt;support email&gt;</code></li> <li>Specify app logo (Optional)</li> </ul> </li> <li>Enter the App domain information.<ul> <li>Application home page: <code>http://localhost:4200</code> (OpenChallenges web app)</li> <li>Authorized domain 1: <code>openchallenges.org</code> (Optional)</li> </ul> </li> <li>Enter the Developer contact information.<ul> <li>Email addresses: <code>&lt;contact addresses&gt;</code></li> </ul> </li> <li>Click on <code>Save and Continue</code>.</li> <li>Enter Scopes information.</li> <li>Click on <code>Add or Remove Scopes</code>.</li> <li>Add these scopes:<ul> <li><code>.../auth/userinfo.email</code></li> <li><code>.../auth/userinfo.profile</code></li> <li><code>openid</code></li> </ul> </li> <li>Click on <code>Update</code>.</li> <li>Click on <code>Save and Continue</code>.</li> <li>Review the app registration information and click on <code>Back to Dashboard</code>.</li> <li>Go back to the Credentials page and click on <code>Create Credentials</code>.</li> <li>Select <code>OAuth client ID</code>.</li> <li>Enter the client ID information.<ul> <li>Application type: <code>Web application</code></li> <li>Name: <code>Challenge Keycloak Test Client</code></li> <li>Authorized redirect URIs</li> <li><code>http://localhost:8080/realms/test/broker/google/endpoint</code></li> </ul> </li> <li>Click on <code>Create</code>.</li> <li>Click on <code>Download JSON</code> to download the Client ID and Client Secret.</li> <li>Click on <code>OK</code>.</li> </ol>"},{"location":"_archive/enable-sso-with-keycloak/#create-a-google-identify-provider-in-keycloak","title":"Create a Google identify provider in Keycloak","text":"<ol> <li>Access the realm in Keycloak Admin console.</li> <li>Left menu &gt; Click on <code>Identify Providers</code></li> <li>Social section &gt; Click on <code>Google</code></li> <li>Note the <code>Redirect URI</code> value which will be used in the next steps.</li> <li>Specify the Client ID and Client Secret in the <code>Add Google provider</code>.</li> <li>Click on <code>Add</code>.</li> </ol>"},{"location":"_archive/enable-sso-with-keycloak/#log-in-to-the-openchallenges-with-a-google-account","title":"Log in to the OpenChallenges with a Google account","text":"<ol> <li>Click on <code>Log In</code>.</li> <li>The option to sign in with Google should now be available. Click on <code>Google</code>.</li> <li>Select your (Sage) Google account.</li> <li>Upon successful login, you should be redirected to the app.</li> </ol>"},{"location":"_archive/enable-sso-with-keycloak/#notes","title":"Notes","text":"<ul> <li>With the above configuration, the username of the user upon registration is set to the Google   email address of the user. We need to find a way to allow the user to specify another username   value during the registration proces.</li> </ul>"},{"location":"_archive/faq/","title":"FAQ","text":""},{"location":"_archive/faq/#unable-to-create-nx-workspace-because-of-gpg-related-bug","title":"Unable to create Nx workspace because of GPG-related bug","text":"<p>The solution is to temporarily disable the git config <code>commit.gpgsign</code>.</p> <pre><code>git config --global commit.gpgsign false\nyarn create nx-workspace openchallenges --preset=empty --packageManager=yarn\ngit config --global commit.gpgsign true\n</code></pre>"},{"location":"_archive/faq/#task-apilint-fails","title":"Task <code>api:lint</code> fails","text":"<pre><code>\u2716  nx run api:lint\n    Loading .env environment variables...\n    Error: the command black could not be found within PATH or Pipfile's [scripts].\n    ERROR: Something went wrong in @nrwl/run-commands - Command failed: pipenv run black ./openapi_server --check --exclude '(models|test)'\n</code></pre> <p>Run <code>nx python api</code> to create the Python virtualenv and install the tools needed.</p>"},{"location":"_archive/faq/#no-space-left-on-device","title":"No space left on device","text":"<p>This error likely happens because the root filesystem is full. Verify whether that is the case by running the following command on the host (not from within the dev container).</p> <pre><code>$ df -h\nFilesystem      Size  Used Avail Use% Mounted on\ndevtmpfs        7.8G     0  7.8G   0% /dev\ntmpfs           7.8G     0  7.8G   0% /dev/shm\ntmpfs           7.8G  692K  7.8G   1% /run\ntmpfs           7.8G     0  7.8G   0% /sys/fs/cgroup\n/dev/nvme0n1p1   50G   50G  679M  99% /\ntmpfs           1.6G     0  1.6G   0% /run/user/1000\n</code></pre> <p>The root filesystem (/) is indeed full. The command below lists the folders starting from the largest one. Make sure to run this command as root, otherwise only the folders visible to the user will be taken into account.</p> <pre><code>[ec2-user@ip-10-41-30-136 ~]$ sudo du -aBM / 2&gt;/dev/null | sort -nr | head -n 50 | more\n53903M  /\n41411M  /var\n40578M  /var/lib\n40455M  /var/lib/docker\n30810M  /var/lib/docker/overlay2\n10171M  /home/ec2-user\n10171M  /home\n9609M   /var/lib/docker/volumes\n8585M   /var/lib/docker/volumes/dind-var-lib-docker/_data\n8585M   /var/lib/docker/volumes/dind-var-lib-docker\n7976M   /var/lib/docker/volumes/dind-var-lib-docker/_data/overlay2\n5184M   /var/lib/docker/overlay2/a4675f542ab8ee863953360af4be4d3ab46fa9743bbb4a0ec56a56a887c8ef52\n...\n</code></pre> <p>Regularly building Docker images filled up the root filesystem. Consider performing the following actions to free up disk space.</p> <p>Remove unused images:</p> <pre><code>docker container prune --force &amp;&amp; docker rmi $(docker images -aq) --force\n</code></pre> <p>Note When using VS Code dev container with the feature <code>docker-in-docker</code>, removing the images on the host won't remove the images in the dev container. If that is the case, you can also run the above command inside the dev container.</p> <p>Prune Docker system:</p> <pre><code>docker system prune\n</code></pre> <p>Prune Docker volumes:</p> <pre><code># remove selected volume\ndocker volume ls\ndocker volume rm &lt;volume name&gt;\n\n# remove all volumes\ndocker volume prune\n</code></pre> <p>Note The volume <code>dind-var-lib-docker</code> is created by the dev container feature <code>docker-in-docker</code>. The volume <code>vscode</code> is created when starting a dev container with VS Code. These two volumes should not be removed if a dev container is running.</p>"},{"location":"_archive/figma-to-code/","title":"Figma to code","text":"<p>Often times, it can be quite time-consuming to go from design concepts to code. With the Challenge Registry, we hope to alleviate this hurdle by utilizing TeleportHQ's Figma-to-code capability. TeleportHQ is an online collaborative platform meant for front-end development, in which a static website can either be built from scratch, or, in our case, from pre-defined components and frames created in Figma.</p>"},{"location":"_archive/figma-to-code/#requirements","title":"Requirements","text":"<ul> <li>Figma account (free plan)</li> <li>TeleportHQ account (free plan)</li> </ul> <p>Note Paid plans are provided for both tools at Sage upon request. Please submit a Jira ticket to Sage IT to request a Figma and/or TeleportHQ license (tag Jake Albrecht for approval). Otherwise, you are allowed up to 3 Figma files and 3 TeleportHQ projects when using the basic (free).</p> <p>Note You will need Edit access to a Figma document in order to use TeleportHQ plugin (see below). If you don't have Edit access to a Figma document that you want to export, make a copy of the Figma document first, then export the copy to TeleportHQ.</p>"},{"location":"_archive/figma-to-code/#getting-started","title":"Getting started","text":"<p>This guide should work with both the web and desktop Figma app.</p> <ol> <li> <p>Download the TeleportHQ plug-in in Figma (this step is only needed once).</p> </li> <li> <p>Create components and frames in Figma as needed.  If a component or frame uses any color and/or text styles, these will also be included in the export. Learn more about creating color and text styles here.</p> </li> <li> <p>When ready, select a frame or component to include in the export.  This is easiest to do from the Layers panel. The export can include multiple components and frames -- hold the <code>cmd</code> key on a Mac or <code>shift</code> key on a Windows to select your desired layers.</p> </li> <li> <p>Right-click on the selected layer(s) from the Layers panel &gt; Plugins &gt; TeleportHQ - Figma to    Code.</p> </li> <li> <p>A pop-up window will be displayed, where you can review the layers, styles, and config that will be included in the export. Used styles will be highlighted in blue.</p> </li> <li> <p>If you already have a TeleportHQ project defined, you can select Copy Layers to Clipboard to manually copy over the layers to the existing project.  Otherwise, click on Export as a new project.  Depending on how many layers have been selected, this can take anywhere from a couple of seconds to 1-2 minutes; you will then be taken to the TeleportHQ platform.</p> </li> </ol>"},{"location":"_archive/figma-to-code/#navigating-teleporthq","title":"Navigating TeleportHQ","text":"<p>Note This section is inspired by TeleportHQ's docs. Some parts are copied over verbatim.</p>"},{"location":"_archive/figma-to-code/#your-workspace","title":"Your workspace","text":"<p>When you enter a project in TeleportHQ, your workspace will consist of three panels.</p>"},{"location":"_archive/figma-to-code/#left-panel","title":"Left panel","text":"<p>By default, the left panel will display Layers &amp; Files. This is further divided into two sections, where the top half will display the pages and components of the project, and the bottom half will display the layers of the selected file/component.</p> <p>Other options for the left panel include: * Elements: the basic building blocks with which you can start building your user interfaces. Most of them correspond to native HTML elements, e.g. Row, Column.  You can drag and drop an element from this panel into the Canvas, or use their keyboard shortcuts.  See their lesson on Elements to learn more. * CSS Classes: sets of styles that can be reused on multiple elements.  TeleportHQ will include some by default.  You can create, search, or edit classes as needed.  See their lesson on CSS Classes to learn more. * Asset manager: allows you to upload your own assets, access directly tens of thousands of images from the Unsplash, and choose icons from several popular libraries.</p>"},{"location":"_archive/figma-to-code/#middle-panel","title":"Middle panel","text":"<p>This is your Canvas, aka where all of the visual building \u2728 magic \u2728 happens.</p>"},{"location":"_archive/figma-to-code/#right-panel","title":"Right panel","text":"<p>When an element is not selected, the right panel will display the Design Language Panel. This is where you can explore and define style tokens used throughout the project.  TeleportHQ includes some styles by default, e.g. \"Primary\" for colors. If your Figma export included color palettes, they will be listed under \"Default\" in the Color tab. Similarly, if your Figma export included text styles, they will be listed individually in the Text tab.</p> <p>When an element is selected, the right panel will change to the Style Inspector Panel, where you can add styles to the elements and/or edit the.</p> <p>Note All tokens defined in the Design Language Panel will be included in the final code export.  Feel free to add/modify/remove tokens as needed, so that the code export only has the definitions you need.</p>"},{"location":"_archive/figma-to-code/#prepare-the-export","title":"Prepare the export","text":"<p>Before exporting to code, we recommend reviewing the Figma-exported elements first, as the Figma-to-TeleportHQ export is not always perfect.</p> <p>For example, let's say you created a set of layers in Figma that is intended to be a button, that is, the layer group includes a shape, a color fill, and some text.  When this gets exported to TeleportHQ, it becomes as a group of layers that are an image (the color fill) and a text block. This  subsequently gets exported as <code>&lt;img&gt;</code> and <code>&lt;span&gt;</code> in the code, which may not be what you intended.</p> <p>Instead, remove the image layer, then apply a CSS class to the parent group.  If you are using one of TeleportHQ's pre-defined CSS classes, you can edit it from the CSS Classes panel. You can alternatively use TeleportHQ's Button element from their Elements panel, and replace the \"button\" layers with it.</p> <p>If there is time or if you are not familiar with editing HTML &amp; CSS, we recommend applying a layout to the Figma-exported project, e.g. applying the Row and Column elements.  Additionally, if responsive design is important in the final product, we recommend using relative sizing and media queries.  See their lesson on Responsive design to learn more.</p> <p>Otherwise, you are more than welcome to add/edit the layout and responsiveness in the exported code.</p>"},{"location":"_archive/figma-to-code/#exporting-the-project","title":"Exporting the project","text":"<ol> <li> <p>In the top-right corner, select Export Project (the icon next to the Publish button).</p> </li> <li> <p>Select Angular or HTML as the library, whichever you are more comfortable with.  Note that exporting as Angular will download the files as a standalone app!</p> </li> <li> <p>Click on the file icon at the bottom of the dropdown to download the project as a zip.</p> </li> </ol>"},{"location":"_archive/figma-to-code/#next-steps","title":"Next steps","text":"<p>After creating a new library and component within the app, copy-paste code from the exported project into the app.  See create-a-new-angular-component for more details on how to create the library and component, and where to copy-paste the code.</p>"},{"location":"_archive/java-cheat-sheet/","title":"Java Cheat Sheet","text":""},{"location":"_archive/java-cheat-sheet/#gradle","title":"Gradle","text":""},{"location":"_archive/java-cheat-sheet/#general","title":"General","text":"<ul> <li>Start a Spring Boot app: <code>./gradlew bootRun</code></li> </ul>"},{"location":"_archive/java-cheat-sheet/#force-tasks-to-execute","title":"Force tasks to execute","text":"<p>You can force Gradle to execute all tasks ignoring up-to-date checks using the <code>--rerun-tasks</code> option:</p> <pre><code>./gradlew test --rerun-tasks\n</code></pre>"},{"location":"_archive/java-cheat-sheet/#suppress-progress-logging","title":"Suppress progress logging","text":"<p>To disable the progress logging we can set the option <code>--console=plain</code> the environment variable TERM to the value dumb. To make it a default behavior, add <code>org.gradle.console=plain</code> to <code>gradle.properties</code> file.</p> <pre><code>./gradlew test --console=plain\nTERM=dumb ./gradlew test\n</code></pre>"},{"location":"_archive/legacy-repositories/","title":"Legacy Repositories","text":"<p>This table lists the repositories used to develop the individual components of the Challenge Registry. Since XXX, the codebase of these components is maintained in this monorepo.</p> Repository Monorepo Project Sage-Bionetworks/rocc-app apps/web-app Sage-Bionetworks/rocc-service apps/api Sage-Bionetworks/rocc-client-angular libs/api-client-angular Sage-Bionetworks/rocc-client-r libs/api-r Sage-Bionetworks/rocc-schemas libs/openchallenges/api-description"},{"location":"_archive/libraries/","title":"Libraries","text":"<p>This document explains how to create Angular and Web Components libraries.</p>"},{"location":"_archive/libraries/#angular-library","title":"Angular library","text":""},{"location":"_archive/libraries/#creating-the-library","title":"Creating the library","text":"<pre><code>nx g @nx/angular:lib awesome-lib [--dry-run]\n</code></pre> <p>The library is added to <code>tsconfig.base.json</code>, which will make it available to other projects.</p>"},{"location":"_archive/libraries/#example","title":"Example","text":"<p>Creation of the UI library for the web-app in <code>libs/web/ui</code>.</p> <pre><code>nx g @nx/angular:lib ui --directory web\nnx g @nx/angular:component footer --project=web-ui\n</code></pre>"},{"location":"_archive/libraries/#web-components-library","title":"Web Components library","text":""},{"location":"_archive/libraries/#creating-the-library_1","title":"Creating the library","text":"<pre><code>nx g @nx/web:lib ui-footer [--dry-run]\n</code></pre> <p>The library is added to <code>tsconfig.base.json</code>, which will make it available to other projects.</p>"},{"location":"_archive/libraries/#fix-eslint-no-undef","title":"Fix eslint <code>no-undef</code>","text":"<p>ESLint is expected to show errors like the ones shown below. The reason is because it does not see their definition, which are provided by the DOM. The solution is to disable the ESLint rule <code>no-undef</code> in the <code>.eslintrc.json</code> of the library. TypeScript already provides this check.</p> <pre><code>'HTMLElement' is not defined (eslint `no-undef`)\n'customElements' is not defined (eslint `no-undef`)\n</code></pre>"},{"location":"_archive/libraries/#importing-the-library-in-an-angular-app","title":"Importing the library in an Angular app","text":"<p>We need need to register <code>CUSTOM_ELEMENTS_SCHEMA</code> in our app or component module. this will tell the Angular compiler to refrain from throwing errors when seeing non-standard element tags in our templates.</p> <pre><code>import { CUSTOM_ELEMENTS_SCHEMA, NgModule } from '@angular/core';\nimport { BrowserModule } from '@angular/platform-browser';\n\nimport { AppComponent } from './app.component';\nimport { NxWelcomeComponent } from './nx-welcome.component';\nimport { RouterModule } from '@angular/router';\n\n@NgModule({\n  declarations: [AppComponent, NxWelcomeComponent],\n  imports: [BrowserModule, RouterModule.forRoot({ initialNavigation: 'enabledBlocking' })],\n  providers: [],\n  schemas: [CUSTOM_ELEMENTS_SCHEMA],\n  bootstrap: [AppComponent],\n})\nexport class AppModule {}\n</code></pre> <p>Import the UI library in an Angular component.</p> <pre><code>import '@sagebionetworks/ui-footer';\n</code></pre> <p>The component <code>ui-welcome</code> provided by the library can now be used in the HTML file of our Angular component.</p> <pre><code>&lt;ui-welcome title=\"Awesome App\"&gt;&lt;/ui-welcome&gt;\n</code></pre>"},{"location":"_archive/libraries/#importing-the-library-in-the-react-app","title":"Importing the library in the React app","text":"<p>We need to tell React to allow components that are not defined within it. To allow this, we will need to create a type file on the root of the <code>src</code> folder or the React project. Name it <code>intrinsic.d.ts</code> and add inside the following:</p> <pre><code>declare namespace JSX {\n  interface IntrinsicElements {\n    [elemName: string]: any;\n  }\n}\n</code></pre> <p>Use the UI component <code>ui-welcome</code> in React.</p> <pre><code>export function App() {\n  return (\n    &lt;&gt;\n      &lt;ui-welcome title=\"web-app-react\" /&gt;\n    &lt;/&gt;\n  );\n}\n\nexport default App;\n</code></pre>"},{"location":"_archive/libraries/#references","title":"References","text":"<ul> <li>Share Components across Front Ends frameworks using Nx and Web   Components</li> <li>Working with Nx.dev using React, Angular and native web components (Part 1 of 3)</li> </ul>"},{"location":"_archive/linters-and-formatters/","title":"Linters and Formatters","text":""},{"location":"_archive/linters-and-formatters/#overview","title":"Overview","text":""},{"location":"_archive/linters-and-formatters/#linters","title":"Linters","text":"File type File extension Linter Dockerfile <code>Dockerfile</code> hadolint HTML <code>*.html</code> Webhint Java <code>*.java</code> Checkstyle SCSS <code>*.scss</code> VS Code (SCSS) TypeScript <code>*.ts</code> ESLint XML <code>*.xml</code> -"},{"location":"_archive/linters-and-formatters/#webhint","title":"Webhint","text":"<p>Linter:</p> <ul> <li>Webhint - VS Code extension</li> </ul> <p>Linter configuration:</p> <ul> <li><code>.hintrc</code></li> </ul>"},{"location":"_archive/linters-and-formatters/#formatters","title":"Formatters","text":"File type File extension Formatter Package type Dockerfile <code>Dockerfile</code> - HTML <code>*.html</code> Prettier Java <code>*.java</code> google-java-format npm SCSS <code>*.scss</code> VS Code (SCSS) TypeScript <code>*.ts</code> ESLint XML <code>*.xml</code> Prettier <p>Formatter:</p> <ul> <li>Prettier - VS Code extension</li> <li>Prettier - Node.js package</li> </ul> <p>Formatter configuration:</p> <ul> <li><code>.prettierrc</code></li> <li><code>.prettierignore</code></li> </ul>"},{"location":"_archive/linters-and-formatters/#google-java-format","title":"google-java-format","text":"<ul> <li>Package type: <code>npm</code></li> <li>Provided by: <code>package.json</code></li> <li>Binary location: <code>${workspaceRoot}/node_modules/.bin/google-java-format</code></li> <li>Configuration file: None</li> <li>Used by:</li> <li><code>.vscode/settings.json</code></li> </ul>"},{"location":"_archive/linters-and-formatters/#auto-format-code-on-save","title":"Auto Format Code On Save","text":""},{"location":"_archive/linters-and-formatters/#java","title":"Java","text":"<ul> <li>File type(s): <code>*.java</code></li> <li>On Save listener: VS Code extension Run on Save (see <code>.vscode/settings.json</code>)</li> <li>Actions:</li> <li>Run the task <code>format</code> for the affected projects (since last commit) identified by Nx.</li> <li>The task <code>format</code> of Java projects runs <code>@nxrocks/nx-spring-boot:format</code>.</li> <li>The project is formatted using Spotless plugin for Maven or Gradle (see <code>build.gradle</code>).</li> </ul>"},{"location":"_archive/linters-and-formatters/#typescript","title":"TypeScript","text":"<ul> <li>File type(s): <code>*.ts</code></li> <li>On Save listener: VS Code extension ESLint</li> <li>Actions:</li> <li>The VS Code extension ESLint formats the file according to the project config defined in      <code>.eslintrc.json</code>. The ESLint project config file references the ESLint workspace config file.</li> <li>The rules defined in Prettier workspace config <code>.prettierrc</code> are read from ESLint workspace      config file <code>.eslintrc.json</code>.</li> </ul> <p>Notes:</p> <ul> <li>The VS Code extension ESLint format files on save by default. This extension seems to ignore VS   Code settings like <code>\"editor.formatOnSave\": false</code>. To turn off the auto formatting for this   extension:   <pre><code>\"editor.codeActionsOnSave\": {\n  // \"source.fixAll\": false,\n  \"source.fixAll.eslint\": false\n},\n</code></pre></li> </ul>"},{"location":"_archive/nx-readme/","title":"Nx","text":"<p>This project was generated using Nx.</p> <p></p> <p>\ud83d\udd0e Smart, Fast and Extensible Build System</p>"},{"location":"_archive/nx-readme/#adding-capabilities-to-your-workspace","title":"Adding capabilities to your workspace","text":"<p>Nx supports many plugins which add capabilities for developing different types of applications and different tools.</p> <p>These capabilities include generating applications, libraries, etc as well as the devtools to test, and build projects as well.</p> <p>Below are our core plugins:</p> <ul> <li>React</li> <li><code>npm install --save-dev @nrwl/react</code></li> <li>Web (no framework frontends)</li> <li><code>npm install --save-dev @nx/web</code></li> <li>Angular</li> <li><code>npm install --save-dev @nx/angular</code></li> <li>Nest</li> <li><code>npm install --save-dev @nrwl/nest</code></li> <li>Express</li> <li><code>npm install --save-dev @nrwl/express</code></li> <li>Node</li> <li><code>npm install --save-dev @nx/node</code></li> </ul> <p>There are also many community plugins you could add.</p>"},{"location":"_archive/nx-readme/#generate-an-application","title":"Generate an application","text":"<p>Run <code>nx g @nrwl/react:app my-app</code> to generate an application.</p> <p>You can use any of the plugins above to generate applications as well.</p> <p>When using Nx, you can create multiple applications and libraries in the same workspace.</p>"},{"location":"_archive/nx-readme/#generate-a-library","title":"Generate a library","text":"<p>Run <code>nx g @nrwl/react:lib my-lib</code> to generate a library.</p> <p>You can also use any of the plugins above to generate libraries as well.</p> <p>Libraries are shareable across libraries and applications. They can be imported from <code>@sagebionetworks/mylib</code>.</p>"},{"location":"_archive/nx-readme/#development-server","title":"Development server","text":"<p>Run <code>nx serve my-app</code> for a dev server. Navigate to http://localhost:4200/. The app will automatically reload if you change any of the source files.</p>"},{"location":"_archive/nx-readme/#code-scaffolding","title":"Code scaffolding","text":"<p>Run <code>nx g @nrwl/react:component my-component --project=my-app</code> to generate a new component.</p>"},{"location":"_archive/nx-readme/#build","title":"Build","text":"<p>Run <code>nx build my-app</code> to build the project. The build artifacts will be stored in the <code>dist/</code> directory. Use the <code>--prod</code> flag for a production build.</p>"},{"location":"_archive/nx-readme/#running-unit-tests","title":"Running unit tests","text":"<p>Run <code>nx test my-app</code> to execute the unit tests via Jest.</p> <p>Run <code>nx affected:test</code> to execute the unit tests affected by a change.</p>"},{"location":"_archive/nx-readme/#running-end-to-end-tests","title":"Running end-to-end tests","text":"<p>Run <code>nx e2e my-app</code> to execute the end-to-end tests via Cypress.</p> <p>Run <code>nx affected:e2e</code> to execute the end-to-end tests affected by a change.</p>"},{"location":"_archive/nx-readme/#understand-your-workspace","title":"Understand your workspace","text":"<p>Run <code>nx graph</code> to see a diagram of the dependencies of your projects.</p>"},{"location":"_archive/nx-readme/#further-help","title":"Further help","text":"<p>Visit the Nx Documentation to learn more.</p>"},{"location":"_archive/nx-readme/#nx-cloud","title":"\u2601 Nx Cloud","text":""},{"location":"_archive/nx-readme/#distributed-computation-caching-distributed-task-execution","title":"Distributed Computation Caching &amp; Distributed Task Execution","text":"<p>Nx Cloud pairs with Nx in order to enable you to build and test code more rapidly, by up to 10 times. Even teams that are new to Nx can connect to Nx Cloud and start saving time instantly.</p> <p>Teams using Nx gain the advantage of building full-stack applications with their preferred framework alongside Nx\u2019s advanced code generation and project dependency graph, plus a unified experience for both frontend and backend developers.</p> <p>Visit Nx Cloud to learn more.</p>"},{"location":"_archive/nx-tags/","title":"Nx tags","text":""},{"location":"_archive/nx-tags/#tag-type","title":"Tag <code>type</code>","text":"<p>Values:</p> <ul> <li><code>type:app</code></li> <li><code>type:service</code></li> <li><code>type:db</code></li> <li><code>type:feature</code></li> <li><code>type:util</code></li> <li><code>type:assets</code></li> <li><code>type:styles</code></li> <li><code>type:themes</code></li> </ul> <p>Candidate values:</p> <ul> <li><code>type:angular</code></li> <li><code>type:react</code></li> <li><code>type:model</code></li> </ul>"},{"location":"_archive/nx-tags/#tag-scope","title":"Tag <code>scope</code>","text":"<p>Values:</p> <ul> <li><code>scope:client</code></li> <li><code>scope:admin</code></li> <li><code>scope:backend</code></li> <li><code>scope:shared</code></li> </ul>"},{"location":"_archive/projects/","title":"Challenge Projects","text":""},{"location":"_archive/projects/#applications","title":"Applications","text":"Project Description challenge-api-gateway API gateway challenge-elasticsearch Elasticsearch challenge-keycloak Access and Identity Management (IAM) challenge-kibana Visualization dashboard for Elasticsearch challenge-logstash Data processing pipeline for Elasticsearch challenge-mariadb MariaDB database challenge-mongodb MongoDB database challenge-postgresql PostgreSQL database openchallenges OpenChallenges application openchallenges-e2e OpenChallenges E2E test challenge-service-registry Service registration and discovery"},{"location":"_archive/projects/#libraries","title":"Libraries","text":"Project Description openchallenges-about OpenChallenges About page openchallenges-assets OpenChallenges assets openchallenges-auth OpenChallenges AuthN/AuthZ openchallenges-challenge OpenChallenges Challenge page openchallenges-challenge-search OpenChallenges Challenge search page openchallenges-config OpenChallenges configuration openchallenges-home OpenChallenges Home page openchallenges-not-found OpenChallenges Not found page openchallenges-org-profile OpenChallenges Organization profile page openchallenges-org-search OpenChallenges Organization search page openchallenges-signup OpenChallenges Signup page openchallenges-styles OpenChallenges SCSS styles openchallenges-themes OpenChallenges SCSS themes openchallenges-ui OpenChallenges reusable UI components openchallenges-user-profile OpenChallenges User profile page shared-assets Assets shared by multiple TypeScript projects shared-java-util Util library shared by multiple Java projects shared-styles SCSS styles shared by multiple TypeScript projects shared-theme SCSS themes shared by multiple TypeScript projects shared-util Util library shared by multiple TypeScript projects shared-web-components Web Components shared by multiple web projects"},{"location":"_archive/references/","title":"References","text":""},{"location":"_archive/references/#nx","title":"Nx","text":""},{"location":"_archive/references/#libraries","title":"Libraries","text":"<ul> <li>Library Types</li> <li>Grouping Libraries</li> </ul>"},{"location":"_archive/references/#plugins","title":"Plugins","text":"<ul> <li>Approved plugins</li> </ul>"},{"location":"_archive/search-engine-optimization/","title":"Search Engine and Social Media Optimization","text":""},{"location":"_archive/search-engine-optimization/#create-local-http-tunnel-with-ngrok","title":"Create local HTTP tunnel with ngrok","text":"<ol> <li>Create an ngrok account.</li> <li>Copy your token from Getting Started &gt; Your Authtoken.</li> <li>Install the ngrok client.</li> <li>Authenticate witn your ngrok token.     <pre><code>ngrok config add-authtoken &lt;token&gt;\n</code></pre></li> <li>Start the HTTP tunnel, for example for the Angular app that listens to the port 4200.     <pre><code>ngrok http --host-header=rewrite 4200\n</code></pre></li> </ol>"},{"location":"_archive/search-engine-optimization/#curl-a-page-as-a-bot","title":"Curl a page as a bot","text":"<p>We can send the name of the agent - here <code>Twitterbot</code> - to the server. This information could be used by the server during dynamic rendering.</p> <pre><code>curl -A Twitterbot http://localhost:4200\n</code></pre>"},{"location":"_archive/stack-monitoring/","title":"Stack Monitoring","text":""},{"location":"_archive/stack-monitoring/#start-the-elk-stack","title":"Start the ELK stack","text":"<p>Run this command to start the ELK stack in your local environment.</p> <pre><code>challenge-elk-serve-detach\n</code></pre> <p>Open Kibana in your browser at http://localhost:5601.</p> <p>Note Only the logs of dockerized apps are captured at this time.</p>"},{"location":"_archive/stack-monitoring/#access-the-app-logs","title":"Access the app logs","text":"<ol> <li>Log in to Kibana</li> <li>Local ELK stack:<ul> <li>Username: <code>elastic</code></li> <li>Password: <code>changeme</code></li> </ul> </li> <li>Click on Kibana app menu (three-line icon) &gt; Logs.</li> <li>Filter logs, e.g.</li> <li>by Docker container name: <code>docker.name:\"/challenge-logstash\"</code>.</li> <li>by timestamp using the dedicated UI component.</li> </ol>"},{"location":"_archive/update-dependencies/","title":"Updating tools and dependencies","text":"<ul> <li>Renovate</li> <li>Dependency update workflow<ul> <li>Exceptions</li> <li>Dev container</li> <li>Yarn</li> </ul> </li> </ul>"},{"location":"_archive/update-dependencies/#renovate","title":"Renovate","text":"<p>This workspace manages dependency updates using Renovate, which is controlled by a GitHub workflow. The main benefit of Renovate is that its behavior can be fully customized, unlike Dependabot's. For example, the following strategies are used to minimize the number of email/in-app notifications:</p> <ul> <li>Define when Renovate runs</li> <li>Group several dependency updates in a single PR</li> <li>Limit the number of PRs that Renovate can open at a given time</li> <li>Merge dependency updates automatically, thus avoiding the notification that would have come with   the creation of a PR. <p>Note This strategy is probably viable only for projects that have a high level of test coverage.</p> </li> </ul> <p>Renovate provides this dashboard to manage dependency updates. The following section describes the workflow currently applied to update the dependencies.</p>"},{"location":"_archive/update-dependencies/#dependency-update-workflow","title":"Dependency update workflow","text":"<p>Note This workflow is a work in progress.</p> <ol> <li>Go to Renovate's dashboard.</li> <li>Review the dependency updates listed in the section \"Open\", for which a PR is already open.     &gt; Note Currently, Renovate is configured to open up to 5 PRs for the sake of reducing     &gt; notifications.</li> <li>Merge the PRs that you are confident will not break the workspace.     &gt; Note For PRs that affect projects with low test coverage, it is recommended to checkout     &gt; the branch locally and manually test that the main projects still work (e.g. the Challenge     &gt; Registry app).</li> <li>Trigger the creation of PRs from the dashboard for dependencies listed in the section    \"Rate-Limited\" (minor and patch updates) that you are confident you can merge according to the    criteria listed in Step 3.</li> <li>Trigger the creation of PRs from the dashboard for dependencies listed in the section \"Pending    Approval\" (major updates) that you are confident you can merge according to the criteria listed    in Step 3.</li> </ol>"},{"location":"_archive/update-dependencies/#exceptions","title":"Exceptions","text":"<p>The following tools must be updated manually as described. Continuing to ask Renovate to report on updates available for these dependencies is still benefitial. One improvement could be to prevent Renovate from automatically opening PRs for these tools. Once dependencies have been manually updated, Renovate will automatically remove the corresponding items from the dashboard.</p> <ul> <li>Major updates of Nx, Angular and Jest must be applied using Nx [<code>migrate</code> tool]. Nx will take care   of updating its version number as well as the version number of supported tools like Angular and   Jest. Nx will also modify files like the <code>project.json</code> files.</li> <li>Node.js and Yarn are installed as part of the dev container. Renovate's attempts to update these   tools are currently making the CI/CD workflow fail because Renovate does not detect their version   numbers defined in the dev container Dockerfile.</li> </ul>"},{"location":"_archive/update-dependencies/#dev-container","title":"Dev container","text":"<p>The workflow used to update the dev container is described in this ticket.</p>"},{"location":"_archive/update-dependencies/#yarn","title":"Yarn","text":"<ol> <li>Update the version of <code>yarn</code> in the Dockerfile of the devcontainer.</li> <li>Rebuild and restart the devcontainer.</li> <li>Update the version of <code>yarn</code> used in the workspace.     <pre><code>yarn set version &lt;version&gt;\n</code></pre></li> </ol>"},{"location":"_archive/update-dependencies/#attic","title":"Attic","text":""},{"location":"_archive/update-dependencies/#nodejs","title":"Node.js","text":"<p>Identify whether a new version is available for a package.</p> <pre><code>yarn outdated &lt;package&gt;\n</code></pre> <p>Update the package.</p> <pre><code>yarn upgrade &lt;package&gt; --latest\n</code></pre> <p>Example:</p> <pre><code>$ yarn outdated @nxrocks/nx-spring-boot\nyarn outdated v1.22.19\ninfo Color legend :\n \"&lt;red&gt;\"    : Major Update backward-incompatible updates\n \"&lt;yellow&gt;\" : Minor Update backward-compatible features\n \"&lt;green&gt;\"  : Patch Update backward-compatible bug fixes\nPackage                 Current Wanted Latest Package Type    URL\n@nxrocks/nx-spring-boot 4.0.2   4.1.0  4.1.0  devDependencies https://github.com/tinesoft/nxrocks/blob/master/packages/nx-spring-boot#readme\nDone in 4.26s.\n\n$ yarn upgrade @nxrocks/nx-spring-boot --latest\n...\nsuccess Saved 2 new dependencies.\ninfo Direct dependencies\n\u2514\u2500 @nxrocks/nx-spring-boot@4.1.0\ninfo All dependencies\n\u251c\u2500 @nxrocks/common@1.1.0\n\u2514\u2500 @nxrocks/nx-spring-boot@4.1.0\nDone in 162.06s.\n</code></pre>"},{"location":"_archive/using-nx/","title":"Using Nx","text":""},{"location":"_archive/using-nx/#developer-workflow","title":"Developer Workflow","text":"<p>Embracing the monorepo-style development often requires some changes to the development workflow.</p> <p>Our CI should run the following checks:</p> <ul> <li>It checks that the changed code is formatted properly (<code>nx format:check</code>).</li> <li>It runs lint checks for all the projects affected by a PR/commit.</li> <li>It runs unit tests for all the projects affected by a PR/commit.</li> <li>It runs e2e tests for all the apps affected by a PR/commit.</li> <li>It rebuilds all the apps affected by a PR/commit.</li> </ul> <p>Note all the projects affected by a PR/commit. This is very important. Monorepo-style development only works if we rebuild, retest, and relint only the projects that can be affected by our changes. If we instead retest everything, we will get the the following problems:</p> <ul> <li>The performance of CI checks will degrade over time. The time it takes to run the CI checks should   be proportional to the impact of the change, not the size of the repo.</li> <li>We will be affected by the code your change didn\u2019t touch</li> </ul> <p>We should utilize <code>affected:*</code> commands to build and test projects. Read more about them here.</p>"},{"location":"_archive/using-nx/#trunk-based-development","title":"Trunk-based development","text":"<p>Monorepo-style development works best when used with trunk-based development.</p> <p>When using trunk-based development, we have a single main branch (say <code>main</code>) where every team submits their code. And they do it as soon as possible. So if someone works on a large feature, they split it into a few small changes that can be integrated into <code>main</code> in a week. In other words, when using trunk-based development, teams can create branches, but they are short-lived and focus on a specific user story.</p> <p>One issue folks often raise in regards to trunk-based development is \"things change under you while you are trying to create a release\". This can definitely happen, especially when manual testing is involved. To mitigate we can create a release branch where we would cherry-pick commits from <code>main</code> to. With this, we can still frequently merge code into <code>main</code> and have our release isolated from changes made by other teams.</p>"},{"location":"_archive/using-nx/#code-organization-naming-conventions","title":"Code Organization &amp; Naming Conventions","text":""},{"location":"_archive/using-nx/#apps-and-libs","title":"Apps and Libs","text":"<ul> <li>Apps configure dependency injection and wire up libraries. They should not contain any components,   services, or business logic.</li> <li>Libs contain services, components, utilities, etc. They have well-defined public API.</li> </ul> <p>A typical Nx workspace has many more libs than apps, so pay especially careful attention to the organization of the libs directory.</p>"},{"location":"_archive/using-nx/#scope-where-a-library-lives-who-owns-it","title":"Scope (Where a library lives, who owns it)","text":"<p>It's a good convention to put applications-specific libraries into the directory matching the application name. This provides enough organization for small to mid-size applications.</p> <p>For example:</p> <pre><code>apps/web-app          &lt;---- app\nlibs/web-app          &lt;---- app-specific libraries\n</code></pre> <p>If more than one web app was added to the monorepo, say <code>booking</code> and <code>check-in</code> for an airline, the file structure would look something like this:</p> <pre><code>apps/booking               &lt;---- app\napps/check-in              &lt;---- app\nlibs/booking               &lt;---- app-specific libraries\nlibs/check-in              &lt;---- app-specific libraries\n</code></pre>"},{"location":"_archive/using-nx/#type-what-is-in-the-library","title":"Type (What is in the library)","text":"<p>With Nx, we can partition our code into small libraries with well-defined public API. So we can categorize our libraries based on what they contain.</p> <ul> <li>Utility libraries contain utilities and services.</li> <li>Data-access can contain NgRx-related code.</li> <li>Component libraries should contain presentational components and directives.</li> <li>Feature libraries contain business logic, application screens, etc.</li> </ul> <p>This categorization is a good starting point, but other library types are quite common too (e.g., mock libraries). It's a good idea to establish naming conventions (e.g., utilities-testing, components-buttons). Having them helps developers explore the code and feel comfortable no matter where they are in the repository.</p>"},{"location":"_archive/using-nx/#managing-dependencies","title":"Managing Dependencies","text":"<p>For a large organization it's crucial to establish how projects can depend on each other. For instance:</p> <ul> <li>Libraries with a broader scope (e.g., <code>shared/ui</code>) should not depend on the libraries with   narrower scope (e.g., <code>happynrwlapp/search/utils-testing</code>).</li> <li>Component libraries should only depend on other component libraries and utility libraries, but   should not depend feature libraries.</li> </ul> <p>Nx provides a feature called tags that can be used to codify and statically-enforce these rules. Read more about tags here.</p>"},{"location":"_archive/using-nx/#code-ownership","title":"Code Ownership","text":"<p>It's crucial for a large company with multiple teams contributing to the same repository to establish clear code ownership.</p> <p>Since Nx allows us to group apps and libs in directories, those directories can become code-ownership boundaries. That's why the structure of an Nx workspace often reflects the structure of an organization. GitHub users can use the CODEOWNERS file for that.</p> <pre><code>/libs/happynrwlapp          julie\n/apps/happynrwlapp          julie\n/libs/shared/ui             hank\n/libs/shared/utils-testing  julie,hank\n</code></pre> <p>If you want to know more about code ownership on Github, please check the documentation on the CODEOWNERS file.</p>"},{"location":"_archive/using-nx/#cheat-sheet","title":"Cheat Sheet","text":"<p>This cheat sheet provides an overview of the commands needed when developing in this monorepo.</p>"},{"location":"_archive/using-nx/#references","title":"References","text":"<p>The content of this document was initially copied-pasted from:</p> <ul> <li>Using Nx at Enterprises</li> </ul>"},{"location":"_archive/vscode-cheat-sheet/","title":"VS Code Cheat Sheet","text":""},{"location":"_archive/vscode-cheat-sheet/#list-the-extensions-installed","title":"List the extensions installed","text":"<pre><code>code --list-extensions --show-versions\n</code></pre>"},{"location":"contributions/bug-report/","title":"Reporting a bug","text":"<p>Issues should be used to report problems with this project, request a new feature, or to discuss potential changes before a pull request (PR) is created. When you create a new issue, a template will be loaded that will guide you through collecting and providing the information we need to investigate.</p> <p>If you find an issue that addresses the problem you're having, please add your own reproduction information to the existing issue rather than creating a new one. Adding a reaction can also help be indicating to our maintainers that a particular problem is affecting more than just the reporter.</p>"},{"location":"contributions/guidelines/","title":"Adding a feature","text":"<p>PRs to our repositories are always welcome and can be a quick way to get your fix or improvement slated for the next release. In general, PRs should:</p> <ul> <li>Only fix/add the functionality in question OR address wide-spread   whitespace/style issues, not both.</li> <li>Add unit or integration tests for fixed or changed functionality (if a test   suite already exists).</li> <li>Address a single concern in the least number of changed lines as possible.</li> <li>Include documentation in the repo or on our [docs site].</li> <li>Be accompanied by a complete Pull Request template (loaded automatically when   a PR is created).</li> </ul> <p>For changes that address core functionality or would require breaking changes (e.g. a major release), it's best to open an Issue to discuss your proposal first. This is not required but can save time creating and reviewing changes.</p> <p>In general, we follow the Forking Workflow:</p> <ol> <li>Fork the repository to your own Github account</li> <li>Clone the project to your machine</li> <li> <p>Create a branch locally with a succinct but descriptive name</p> <p>git checkout -b \uff1cnew-branch\uff1e main</p> </li> <li> <p>Commit changes to the branch</p> </li> <li>Following any formatting and testing guidelines specific to this repo</li> <li>Push changes to your fork</li> <li>Open a PR in our repository and follow the PR template so that we can    efficiently review the changes.</li> </ol> <p>We recommend that you add this repository as an upstream remote to your local git repository so that you can fetch the latest updates.</p> <pre><code>$ git remote add upstream https://github.com/Sage-Bionetworks/sage-monorepo.git\n$ git remote -v\n&gt; ...\n&gt; upstream  https://github.com/Sage-Bionetworks/sage-monorepo.git (fetch)\n&gt; upstream  https://github.com/Sage-Bionetworks/sage-monorepo.git (push)\n</code></pre> <p>On your local machine make sure you have the latest version of the <code>main</code> branch from this upstream repository:</p> <pre><code>git checkout main\ngit fetch upstream\ngit rebase upstream/main\n</code></pre>"},{"location":"contributions/guidelines/#setup-development-environment","title":"Setup Development Environment","text":"<p>This project relies on Node tools and project-specific commands defined in package.json to streamline the development and testing. The command below will install the required development tools.</p> <p>Source <code>dev-env.sh</code>.</p> <pre><code>. dev-env.sh\n</code></pre> <p>Prepare the development environment.</p> <pre><code>openchallenges-prepare\n</code></pre>"},{"location":"contributions/guidelines/#linting","title":"Linting","text":"<p>Lint all the projects.</p> <pre><code>yarn lint\n</code></pre>"},{"location":"contributions/guidelines/#testing","title":"Testing","text":"<p>Build and test all the projects.</p> <pre><code>yarn build\nyarn test\n</code></pre>"},{"location":"contributions/guidelines/#start-the-openchallenges","title":"Start the OpenChallenges","text":"<p>Start the web app and its dependencies (API, API database).</p> <pre><code>yarn start\n</code></pre>"},{"location":"contributions/guidelines/#release-procedure","title":"Release Procedure","text":"<p>Maintainers are required to follow the procedure below when creating a new release.</p> <p>TBA</p>"},{"location":"contributions/guidelines/#getting-help","title":"Getting Help","text":"<p>Join us on the XXX and post your question to the channel that best matches the topic of your request.</p>"},{"location":"contributions/overview/","title":"Overview","text":"<p>Thank you contributing to the Sage Monorepo!  We welcome any and all feedback, ideas, and suggestions.</p> <p>Contributions can be made via issues and pull eequests (PRs).</p> <ul> <li>Reporting a bug</li> <li>Adding a feature</li> </ul>"},{"location":"contributions/overview/#code-of-conduct","title":"Code of Conduct","text":"<p>We take our open source community seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.</p>"},{"location":"developers-guide/creating-a-commit-with-multiple-authors/","title":"Creating a commit with multiple authors","text":""},{"location":"developers-guide/creating-a-commit-with-multiple-authors/#introduction","title":"Introduction","text":"<p>You can attribute a commit to more than one author by adding one or more <code>Co-authored-by</code> trailers to the commit's message. Co-authored commits are visible on GitHub.</p>"},{"location":"developers-guide/creating-a-commit-with-multiple-authors/#when-to-add-co-authors-to-a-commit","title":"When to add co-authors to a commit?","text":"<p>Annotating commits with <code>Co-authored-by</code> is generally encouraged when copying code from other developers.</p> <p>Annotating commits with <code>Co-authored-by</code> is required when you are committing previously-untracked code written by other users.</p> <p>Example</p> <ol> <li>Bea develops a new feature and submits it as a pull request (PR).</li> <li>Eddy is tasked with refactoring Bea's PR into multiple PRs.</li> <li>Eddy copies and pastes code written by Bea and adapts it.</li> <li>Eddy adds Bea as a co-author to the commits that include code she wrote.</li> </ol>"},{"location":"developers-guide/creating-a-commit-with-multiple-authors/#adding-co-authors-to-a-commit","title":"Adding co-authors to a commit","text":"<p>Follow the instructions described here.</p> <p>Preview of the commit creation:</p> <pre><code>$ git commit -m \"Refactor usability tests.\n&gt;\n&gt;\nCo-authored-by: NAME &lt;EMAIL&gt;\nCo-authored-by: ANOTHER-NAME &lt;ANOTHER-EMAIL&gt;\"\n</code></pre>"},{"location":"developers-guide/creating-a-commit-with-multiple-authors/#names-and-emails-of-sage-monorepo-contributors","title":"Names and emails of Sage Monorepo contributors","text":"<p>The name and \"no-reply\" emails of the Sage Monorepo contributors (sorted alphabetically):</p> <pre><code>Co-authored-by: andrewelamb &lt;7220713+andrewelamb@users.noreply.github.com&gt;\n</code></pre> <pre><code>Co-authored-by: gaiaandreoletti &lt;46945609+gaiaandreoletti@users.noreply.github.com&gt;\n</code></pre> <pre><code>Co-authored-by: Lingling &lt;55448354+linglp@users.noreply.github.com&gt;\n</code></pre> <pre><code>Co-authored-by: mdsage1 &lt;122999770+mdsage1@users.noreply.github.com&gt;\n</code></pre> <pre><code>Co-authored-by: Rongrong Chai &lt;73901500+rrchai@users.noreply.github.com&gt;\n</code></pre> <pre><code>Co-authored-by: sagely1 &lt;114952739+sagely1@users.noreply.github.com&gt;\n</code></pre> <pre><code>Co-authored-by: Thomas Schaffter &lt;3056480+tschaffter@users.noreply.github.com&gt;\n</code></pre> <pre><code>Co-authored-by: Verena Chung &lt;9377970+vpchung@users.noreply.github.com&gt;\n</code></pre> <p>Note</p> <p>The names, usernames and user IDs of the contributors are collected from their GitHub profile pages. If a contributor does not specify their name on the profile page, the listing uses their username instead of their name. The user ID can be found in the URL of the user's avatar.</p>"},{"location":"developers-guide/creating-a-commit-with-multiple-authors/#references","title":"References","text":"<ul> <li>Creating a commit with multiple   authors</li> </ul>"},{"location":"developers-guide/developing-on-a-remote-host/","title":"Developing on a remote host","text":""},{"location":"developers-guide/developing-on-a-remote-host/#introduction","title":"Introduction","text":"<p>Team members who develop locally may not benefit from the same compute resources. The most notable resources that can impact the productivity of developers are the number and frequency of the CPU cores, the memory available and internet speed. The worse case is when a machine does not have the resources to run the apps that the team develops, for example when not enough memory is available. On other times, the time required to complete a task may be many times slower on a computer with lower CPU resources.</p> <p>Moreover, working remotely means that developers no longer benefit from the same internet speed, either because of the quality of the internet connection available at their location or because the speed is shared among the members of a household. As a result, tasks that involve downloading or uploading artifacts, like pulling or pushing Docker images, may take significantly longer to complete.</p> <p>This page describes how to setup a environment that enables developers to use VS Code while using the compute resources of a remote host.</p>"},{"location":"developers-guide/developing-on-a-remote-host/#motivation","title":"Motivation","text":"<p>To illustrate the benefit of developing on a remote host, this table summarizes the local compute resources available to the developers of OpenChallenges in 2023. The same information is displayed for two types of Amazon EC2 instances and one type of GitHub Codespace instance that were selected as candidate alternative development environments for the team members. The table also includes the runtimes in seconds of different tasks such as linting or testing all the projects included in the monorepo (the method used to generate these results is described in the next section).</p> Shirou Rin Sakura m5.2xlarge t3a.xlarge 4-core Codespace 8-core Codespace Computer Type Desktop PC MacBook Pro MacBook Pro Amazon EC2 Amazon EC2 GitHub Codespace GitHub Codespace Architecture 64-bit (x86) 64-bit (x86) 64-bit (x86) 64-bit (x86) 64-bit (x86) 64-bit (x86) 64-bit (x86) CPU Count 8 4 4 8 4 4 8 CPU Frequency (GHz) 3.6 2.4 1.7 2.5 2.2 2.7 2.8 Memory (GB) 32 16 16 32 16 8 16 Runtime: Lint All Projects (s) 15.4 208.9 183.8 18.6 33.4 24.6 16.9 Runtime: Build All Projects (s) 19.4 196.2 162.2 26.7 44.9 32.3 14.1 Runtime: Test All Projects (s) 12.4 117.1 82.8 15.3 29.2 31.6 24.5 Runtime: Test api (s) 6.2 29.6 21.3 7.2 10.4 6.5 6.5 Runtime: Test web-app (s) 5.3 43.0 35.0 6.5 9.2 6.7 6.0 Download speed (Mbit/s) 395.9 52.1 160.1 2165.0 1606.7 8571 8603 Upload speed (Mbit/s) 183.3 15.6 10.3 1861.0 1030.2 4893 5125 On-Demand Cost ($/day) n/a n/a n/a 9.2 3.6 8.64 (1,2) 17.28 (1,2) On-Demand Cost ($/year) n/a n/a n/a 3363.8 1317.5 3153.6 (1,2) 6307.2 (1,2) <p>(1) GitHub codespaces stop automatically after 1h of inactivity. A codespace used by an full-time engineer (8h/day) - without taking into account vacation for the sake of simplicity - would cost 8 hours/day * 5 days/week * 52 weeks * $0.36/hour (4-core) = $748/year (see Codespaces pricing). Similarly, the cost for an 8-core codespace would become $1496/year. In addition, GitHub bills $0.07 of GB of storage independently on whether the codespace is running or stopped. Pricing valid on 2023-12-31.</p> <p>(2) GitHub offers core hours and storage. For example, a Free user can use a 2-core instance for 60 hours per month for free or an 8-core instance for 15 hours. You will be notified by email when you have used 75%, 90%, and 100% of your included quotas.   - Free users: 120 core hours/month and 15 GB month of storage   - Pro users: 180 core hours/month and 20 GB month of storage</p> <p>Note</p> <p>Note that developers have been asked to measure runtimes and internet speeds while keeping open the applications that are usually running when they develop (e.g. Spotify, several instances of VS Code, browser with many tabs open). This could be one reason why runtimes reported by a developer are larger that those reported by another developer who has less compute resources available.</p> <p>The table below shows the number of times a task ran by a developer is faster than the slowest runtime (denoted by \"1.0\").</p> Shirou Rin Sakura m5.2xlarge t3a.xlarge Runtime: Lint All Projects 13.6 1.0 1.1 11.2 6.3 Runtime: Build All Projects 10.1 1.0 1.2 7.3 4.4 Runtime: Test All Projects 9.4 1.0 1.4 7.6 4.0 Runtime: Test api 4.8 1.0 1.4 4.1 2.8 Runtime: Test web-app 8.0 1.0 1.2 6.6 4.6 Download speed 7.6 1.0 3.1 41.5 30.8 Upload speed 17.8 1.5 1.0 180.5 99.9 <p>For example, linting all the projects of this monorepo is 13.6 times faster on Shirou's computer than on Rin's. Moreover, all the developers can benefit from improved download speeds (up to 41.5 faster for Rin) and upload speeds (up to 180.5 times faster for Sakura) when developing on an EC2 instance. This table illustrates well the diversity in compute resources available locally to developers, and how relying on remote hosts like EC2 instances can provide a better working environment to developers.</p>"},{"location":"developers-guide/developing-on-a-remote-host/#collectings-os-info-and-benchmarking-tasks","title":"Collectings OS info and benchmarking tasks","text":"<p>Runtimes are obtained from this commit.</p> <p>Identification of the compute resources.</p> <pre><code>$ nproc\n$ cat /proc/cpuinfo\n$ cat /proc/meminfo\n</code></pre> <p>Runtimes are averaged over 10 runs that follow a warmup run using hyperfine.</p> <pre><code>$ hyperfine --warmup 1 --runs 10 'nx run-many --all --target=lint --skip-nx-cache'\n$ hyperfine --warmup 1 --runs 10 'nx run-many --all --target=build --skip-nx-cache'\n$ hyperfine --warmup 1 --runs 10 'nx run-many --all --target=test --skip-nx-cache'\n$ hyperfine --warmup 1 --runs 10 'nx test api --skip-nx-cache'\n$ hyperfine --warmup 1 --runs 10 'nx test web-ui --skip-nx-cache'\n</code></pre> <p>Internet speeds are measured with speedtest-cli.</p> <pre><code>$ speedtest\n</code></pre>"},{"location":"developers-guide/developing-on-a-remote-host/#preparing-the-remote-host-aws-ec2","title":"Preparing the remote host - AWS EC2","text":"<p>This section describes how to instantiate an AWS EC2 as the remote host. Steps outlined below will assume you have access to the Sage AWS Service Catalog.</p>"},{"location":"developers-guide/developing-on-a-remote-host/#creating-the-ec2-instance","title":"Creating the EC2 instance","text":"<ol> <li>Log in to the Service Catalog with your Synapse credentials.</li> <li>From the list of Products, select EC2: Linux Docker. On the Product page, click on Launch product in the upper-right corner.</li> <li>On the next page, fill out the wizard as follows:<ul> <li>Provisioned product name<ul> <li>Name: <code>{GitHub username}-devcontainers-{yyyymmdd}</code></li> <li>Example: <code>tschaffter-devcontainers-20240404</code></li> </ul> </li> <li>Parameters<ul> <li>EC2 Instance Type: <code>t3a.2xlarge</code></li> <li>Base Image: <code>AmazonLinuxDocker</code> (leave default)</li> <li>Disk Size: 80</li> </ul> </li> <li>Manage tags<ul> <li><code>CostCenter</code>: Select the Cost Center associated to your project</li> </ul> </li> <li>Enable event notifications: SKIP - DO NOT MODIFY</li> </ul> </li> <li>Click on Launch product. Your instance will take anywhere between 3-5 minutes to deploy. You can either wait on this page until \"EC2Instance\" shows up on the list under Resources, or you can leave and come back at a later time.</li> </ol>"},{"location":"developers-guide/developing-on-a-remote-host/#stopping-the-ec2-instance","title":"Stopping the EC2 instance","text":"<p>It's not something you should do now as part of this tutorial. This section serves as a reminder that AWS charges for evey hour the EC2 instance is running. As soon as you identify that you will no longer need the instance for the rest of the day, open the Service Catalog to stop it.</p> <ol> <li>Open the Service Catalog, then select Provisioned products.</li> <li>Select the EC2 instance.</li> <li>Click on the button Actions &gt; Service actions &gt; Stop.</li> <li>Confirm the action.</li> </ol> <p>After a few seconds, the EC2 instance will be stopped.</p> <p>Note</p> <p>AWS still charges us for the storage space that the EC2 instance takes even when it's not running. Consider destroying the EC2 instance when you decide that you will no longer need it.</p>"},{"location":"developers-guide/developing-on-a-remote-host/#connecting-to-the-ec2-instance-with-aws-console","title":"Connecting to the EC2 instance with AWS Console","text":"<p>We will now use the AWS Console to open a terminal to the EC2 instance and setup your public SSH key.</p> <p>Note</p> <p>This section assumes that you already have a public and private SSH key created on your local machine from where you are running VS Code.</p> <ol> <li>Open the Service Catalog, then select Provisioned products.</li> <li>In the section Resources, click on the link for \"EC2Instance\".</li> <li>Click on the checkbox of the new EC2 instance created.</li> <li>Click on the button Actions &gt; Connect.<ul> <li>The error \"Failed to describe security groups\" shown by AWS can be ignored.</li> </ul> </li> <li>Click on the tab Session Manager.</li> <li>Click on Connect.</li> </ol>"},{"location":"developers-guide/developing-on-a-remote-host/#configuring-the-ssh-public-key-on-the-ec2-instance","title":"Configuring the SSH public key on the EC2 instance","text":"<ol> <li>Login as the user <code>ec2-user</code> and move to its home directory.     <pre><code>$ sudo -s\n# su ec2-user\n$ cd\n</code></pre></li> <li>Create the folder <code>~/.ssh</code> (if needed).     <pre><code>$ mkdir ~/.ssh\n$ chmod 700 ~/.ssh\n</code></pre></li> <li>Create the file <code>~/.ssh/authorized_keys</code> (if needed).     <pre><code>$ touch ~/.ssh/authorized_keys\n$ chmod 644 ~/.ssh/authorized_keys\n</code></pre></li> <li>Copy and paste your public SSH key at the end of <code>~/.ssh/authorized_keys</code>.</li> <li>Click on the button Terminate to terminate the session and confirm the action.</li> </ol>"},{"location":"developers-guide/developing-on-a-remote-host/#configuring-ssh-on-the-local-machine","title":"Configuring SSH on the local machine","text":"<p>This section describes how to create a profile for the EC2 instance in your local <code>~/.ssh/config</code> file.</p> <p>Note</p> <p>This section assumes that you already have a public and private SSH key created on your local machine from where you are running VS Code.</p> <p>First, you need to identify the private IP address of the EC2 instance.</p> <ol> <li>Open the Service Catalog, then select Provisioned products.</li> <li>In the section Outputs, the private IP address is the value associated to    \"EC2InstancePrivateIpAddress\".</li> </ol> <p>Then, on your local machine:</p> <ol> <li>Create the file <code>~/.ssh/config</code> (if needed).     <pre><code>$ touch ~/.ssh/config\n$ chmod 600 ~/.ssh/config\n</code></pre></li> <li>Add the following content to your local <code>~/.ssh/config</code>.     <pre><code>Host {alias}\n    HostName {private ip}\n    User ec2-user\n    IdentityFile {path to your private SSH key, e.g. ~/.ssh/id_rsa}\n</code></pre>     where the placeholder values <code>{...}</code> should be replaced with the correct values.</li> </ol>"},{"location":"developers-guide/developing-on-a-remote-host/#connecting-to-the-ec2-instance-with-vs-code","title":"Connecting to the EC2 instance with VS Code","text":"<ol> <li>Connect to the Sage VPN.</li> <li>Open VS Code.</li> <li>Install the VS Code extension pack \"Remote Development\".</li> <li>Open the command palette with <code>Ctrl+Shit+P</code>.</li> <li><code>Remote-SSH: Connect to Host...</code> &gt; Select the host.</li> <li>Answer the prompts</li> </ol> <p>You are now connected to the EC2 instance! \ud83d\ude80</p> <p>Tip</p> <p>Please remember to stop the EC2 instance at the end of your working day to save on costs.</p>"},{"location":"developers-guide/developing-on-a-remote-host/#next","title":"Next","text":"<p>Go to the section XXX for the instructions on how to setup your environment to contribute to Sage Monorepo.</p>"},{"location":"developers-guide/developing-on-a-remote-host/#preparing-the-remote-host-github-codespace","title":"Preparing the remote host - GitHub Codespace","text":"<p>This section describes how to open your fork of Sage Monorepo in a GitHub Codespaces instance.</p> <p>Note</p> <p>In practice, we will prefer to develop in an EC2 instance created from the Service Catalog for security and budget reasons. Please refer to the instructions given above. Using a GitHub Codespace has been proven to be ponctually useful for quick tests that require a fresh environment, as one of Codespaces benefits is that they can be created and destroyed faster than EC2 instances.</p> <ol> <li>Open your browser and go to GitHub Codespaces.</li> <li>Click on the \"New codespace\".</li> <li>Enter the information requested:<ul> <li>Repository: Select your fork of the monorepo</li> <li>Branch: Select the default branch</li> <li>Dev container configuration: Select the dev container definition</li> <li>Region: Select your preferred region</li> <li>Machine type: Select the machine type</li> </ul> </li> <li>Click on \"Create codespace\".</li> <li>Wait for the codespace to be created.</li> <li>Configure the monorepo and install its dependencies (see README).</li> </ol>"},{"location":"developers-guide/developing-on-a-remote-host/#stopping-a-codespace-instance","title":"Stopping a Codespace instance","text":"<p>If your codespace is open in your browser, you can stop it with the following step. Note that a codespace stops automatically after one hour of inactivity.</p> <ol> <li>Click on the button \"Codespaces\" located in the bottom-left corner.</li> <li>Click on \"Stop Current Codespace\".</li> </ol>"},{"location":"developers-guide/developing-on-a-remote-host/#opening-a-codespace-with-vs-code","title":"Opening a Codespace with VS Code","text":"<p>If you prefer to develop with VS Code rather than inside your browser:</p> <ol> <li>Open your browser and go to GitHub Codespaces.</li> <li>Find the codespace that you want to open with VS Code.</li> <li>Click on the three-dot menu &gt; \"Open in ...\" &gt; \"Open in Visual Studio Code\"</li> </ol>"},{"location":"developers-guide/developing-on-a-remote-host/#changing-the-machine-type","title":"Changing the machine type","text":"<p>The type of machine used by a codespace can be changed at any time, for example when a beefier codespace instance is needed. To change the machine type of an existing codespace.</p> <ol> <li>Stop the codespace.</li> <li>Open your browser and go to GitHub Codespaces.</li> <li>Find the codespace that you want to open with VS Code.</li> <li>Click on the three-dot menu &gt; \"Change machine type\".</li> <li>Update the properties of the machine and click on \"Update codespace\".</li> </ol>"},{"location":"developers-guide/developing-on-a-remote-host/#accessing-apps-and-services","title":"Accessing apps and services","text":"<p>The devcontainer provided with this project uses the VS Code devcontainer feature <code>docker-in-docker</code>. In addition to isolating the Docker engine running in the devcontainer from the engine running on the host, this feature enables VS Code to forward the ports defined in <code>devcontainer.json</code> to the local envrionment of the developer. Therefore, apps and services can be accessed using the address <code>http://localhost</code> even though they are running on the remote host!</p> <p>Accessing the apps and services using the IP address of the remote host won't work, unless you replace the feature <code>docker-in-docker</code> by <code>docker-from-docker</code>. In this case, <code>http://localhost</code> can no longer be used to access the apps and services.</p>"},{"location":"developers-guide/developing-on-a-remote-host/#uploading-files","title":"Uploading files","text":"<p>Simply drag and drop files to the VS Code explorer to upload files from your local environment to the remote host.</p>"},{"location":"developers-guide/developing-on-a-remote-host/#closing-the-remote-connection","title":"Closing the remote connection","text":"<p>Click on the button in the bottom-left corner of VS Code and select one of these options:</p> <ul> <li><code>Close Remote Connection</code> to close the connection with the remote host.</li> <li><code>Reopen Folder in SSH</code> if you want to stop the devcontainer but stay connected to the remote host.</li> </ul>"},{"location":"developers-guide/faq/","title":"Common Issues","text":"<p>Content coming soon!</p>"},{"location":"drawio/","title":"draw.io Resources","text":""},{"location":"drawio/#overview","title":"Overview","text":"<p>draw.io (also known as diagrams.net) is a free and open source cross-platform graph drawing software to create diagrams such as flowcharts, wireframes, UML diagrams, organizational charts, and network diagrams.</p> <p>draw.io's integration with GitHub, the fact that it is an open-source project and several quality-of-life features (e.g., ability to set shape connector points and edit path waypoints) make it the preferred tool to create diagrams for this project.</p>"},{"location":"drawio/#workflow","title":"Workflow","text":"<p>The same workflow applies to the development of code and diagrams. See CONTRIBUTING.md for more information on contributing and/or our Forking Workflow approach.</p> <p>Remainders:</p> <ul> <li>Create a new branch in your fork whenever you create or edit a diagram.</li> <li>From draw.io, save the diagram to this branch in your fork.</li> <li>Submit the new or updated diagram via a Pull Request.</li> </ul>"},{"location":"drawio/#naming-conventions","title":"Naming conventions","text":"<ul> <li>Diagram filename</li> <li>Diagram names must be lower kebab case.</li> <li>Use the extension <code>.drawio.svg</code> to enable GitHub to render a preview of the diagram, while   indicating that this is a draw.io file.</li> </ul>"},{"location":"drawio/#create-a-diagram-in-drawio","title":"Create a diagram in draw.io","text":"<ol> <li>Open your browser and navigate to draw.io.</li> <li>Log in with your GitHub account.</li> <li>To create a diagram click on File &gt; New....</li> <li>Select the extension <code>Editable Vector Image (.svg)</code>.</li> <li>Enter the name of the diagram and use the extension <code>.drawio.svg</code>.</li> <li>Click on <code>Create</code>.</li> </ol>"},{"location":"drawio/#save-a-diagram-to-drawio","title":"Save a diagram to draw.io","text":"<p>If you are saving a file that has been opened from GitHub,</p> <ol> <li>Click on File &gt; Save (Ctrl + S)</li> <li>Specify a commit message and click on OK.</li> </ol> <p>Otherwise,</p> <ol> <li>Click on File &gt; Save as....</li> <li>Check that the filename has the extension <code>.drawio.svg</code>.</li> <li>Click on <code>GitHub</code>.</li> <li>Enter Value (org/repo/ref): <code>&lt;gh_username&gt;/openchallenges/&lt;branch_name&gt;</code> and click OK.</li> <li>Select the folder <code>docs/drawio/diagrams</code> and click on OK.</li> </ol>"},{"location":"drawio/#open-a-diagram","title":"Open a diagram","text":"<ol> <li>To open a diagram that you have recently open, click on File &gt; Open Recent and select the    diagram.</li> <li>Otherwise, click on File &gt; Open from &gt; GitHub....</li> <li>Enter Value (org/repo/ref): <code>&lt;gh_username&gt;/openchallenges/&lt;branch_name&gt;</code> and click OK.</li> <li>Select a diagram from the folder <code>docs/drawio/diagrams</code> and click on OK.</li> </ol>"},{"location":"drawio/#open-a-project-library","title":"Open a project library","text":"<ol> <li>Click on File &gt; Open Library from... &gt; GitHub....</li> <li>Enter Value (org/repo/ref): <code>&lt;gh_username&gt;/openchallenges/&lt;branch_name&gt;</code> and click OK.</li> <li>Select a library from the folder <code>docs/drawio/libraries</code> and click on OK.</li> </ol>"},{"location":"drawio/#add-an-icon-to-a-library","title":"Add an icon to a library","text":"<ol> <li>Download the icon in svg format that you want to add from the official website.</li> <li>If an official icon in svg format cannot be found, it is accepted to use an unofficial icon as      long as the icon looks identical to the official icon.</li> <li> <p>If an icon can only be found in bitmap format (png, jpg), the icon must be converted to an svg      document. Note that the icon must be embeded in the svg document. Consider this element      taken from an svg file:</p> <ul> <li>\u2714\ufe0f <code>xlink:href=\"data:image/png;base64,&lt;data&gt;</code>: the bitmap icon is encoded in base64      (<code>&lt;data&gt;</code>) and is embedded in the svg file.</li> <li>\u274c <code>xlink:href=\"rest-client.png\"</code>: the bitmap icon is linked in the svg document (the icon      is not embedded).</li> </ul> <p>(e.g., see rest-client.svg).</p> </li> <li> <p>Verify that the icon meets the following requirements.</p> </li> <li>The height of the icon must be 80 pt.</li> <li>The height and width of the svg document must fit the icon.</li> <li>The background of the svg document must be transparent.</li> <li>Open the existing library in draw.io.</li> </ol> <p>Note Import the library from a feature branch that you have created in your fork so that you can submit the new icon in a PR.</p> <ol> <li>Drag and drop the svg file to the library.</li> <li>Click on the <code>Save</code> button that appeared in the header of the library.</li> <li>Submit a PR to the upstream repository.</li> </ol>"},{"location":"drawio/#tips","title":"Tips","text":"<ul> <li>Edit shape fixed connector   points</li> <li>Edit path   waypoints</li> </ul>"},{"location":"getting-started/local-dev/","title":"Develop Locally","text":"<p>Content comming soon!</p>"},{"location":"getting-started/remote-dev/","title":"Develop On a Remote Host","text":"<p>Content comming soon!</p>"},{"location":"getting-started/what-is-angular/","title":"What is Angular Universal?","text":"<p>Content comming soon!</p>"},{"location":"getting-started/what-is-devcontainer/","title":"What is a devcontainer?","text":"<p>Content comming soon!</p>"},{"location":"getting-started/what-is-nx/","title":"What is Nx?","text":"<p>Content comming soon!</p>"},{"location":"reference/agora/","title":"API","text":"<p>Content coming soon!</p>"},{"location":"reference/oc-microservices/","title":"Microservices","text":"<p>Content coming soon!</p>"},{"location":"reference/oc-schemas/","title":"Schemas","text":"<p>Content coming soon!</p>"},{"location":"reference/schematic/","title":"API","text":"<p>Content coming soon!</p>"},{"location":"tutorials/angular/add-api-client/","title":"Add an Angular API client","text":"<p>Content coming soon!</p>"},{"location":"tutorials/angular/add-app/","title":"Create an Angular app","text":"<p>Content coming soon!</p>"},{"location":"tutorials/angular/add-component/","title":"Add an Angular component","text":"<p>Content coming soon!</p>"},{"location":"tutorials/angular/add-library/","title":"Add an Angular library","text":"<p>Content coming soon!</p>"},{"location":"tutorials/docker/new-project/","title":"Create a Docker-based project","text":"<p>Content coming soon!</p>"},{"location":"tutorials/java/add-library/","title":"Add a Java library","text":"<p>Content coming soon!</p>"},{"location":"tutorials/java/add-rest-api/","title":"Add a Java REST API","text":"<p>Content coming soon!</p>"},{"location":"tutorials/r/new-project/","title":"Add an R project","text":"<p>Content coming soon!</p>"}]}